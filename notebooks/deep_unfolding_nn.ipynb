{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "96aa30e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import importlib\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Any\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "# Get the current working directory\n",
    "scripts_dir = os.getcwd()\n",
    "# Go up one level\n",
    "project_root = os.path.abspath(os.path.join(scripts_dir, '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "\n",
    "import src.deep_unfolding_nn\n",
    "importlib.reload(src.deep_unfolding_nn)\n",
    "from src.deep_unfolding_nn import DUNN, Trainer\n",
    "\n",
    "import src.utils\n",
    "importlib.reload(src.utils)\n",
    "from src.utils import sum_rate_loss_BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12242748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj_power(V, PT_sc):\n",
    "    num_users_sc = len(V)\n",
    "    # Projects V according to the constraint\n",
    "    alph = torch.sqrt(torch.tensor(PT_sc)) / torch.sqrt(torch.tensor(sum([torch.trace(V[str(k)] @ V[str(k)].conj().T) for k in range(num_users_sc)])))\n",
    "    V_proj = {str(k): alph * V[str(k)] for k in range(num_users_sc)}\n",
    "    return V_proj\n",
    "\n",
    "def init_V(H):\n",
    "    # Initializes V according to Hu's code\n",
    "    V = {}\n",
    "    for k in range(len(H_dict)):\n",
    "        V[str(k)] = (torch.linalg.pinv(H[str(k)] @ H[str(k)].conj().T) @ H[str(k)]).conj().T\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc983902",
   "metadata": {},
   "outputs": [],
   "source": [
    "class setup():\n",
    "    def __init__(self, n_tx, n_rx, d, num_streams, num_users, PT, sig):\n",
    "        self.n_tx = n_tx\n",
    "        self.n_rx = n_rx\n",
    "        self.d = num_streams\n",
    "        self.K = num_users\n",
    "        self.PT = PT\n",
    "        self.sig = sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5d818b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_up = setup(n_tx=8, n_rx=[2, 2, 2, 2], d=[2, 2, 2, 2], num_streams=[2, 2, 2, 2], num_users=4, PT=5, sig = [.1, .1, .1, .1])\n",
    "# Parameters\n",
    "n_t = set_up.n_tx  # fixed number of transmit antennas\n",
    "n_r = set_up.n_rx  # different receive antennas for each column\n",
    "\n",
    "# Function to generate one complex matrix\n",
    "def complex_matrix(n_t, n_r):\n",
    "    return torch.randn(n_r, n_t, dtype=torch.cfloat)\n",
    "\n",
    "# Construct the DataFrame\n",
    "data = []\n",
    "for _ in range(10):  # 5 rows\n",
    "    row = {f'user_{i}': complex_matrix(n_t, n_r[i]) for i in range(set_up.K)}\n",
    "    data.append(row)\n",
    "\n",
    "H = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b6257868",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/35/f3dbnk6d3ts1993_z878dt5w0000gn/T/ipykernel_29652/2841192314.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  H_dict = {str(i): row[i] for i in range(len(row))}\n",
      "/var/folders/35/f3dbnk6d3ts1993_z878dt5w0000gn/T/ipykernel_29652/4217901526.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  alph = torch.sqrt(torch.tensor(PT_sc)) / torch.sqrt(torch.tensor(sum([torch.trace(V[str(k)] @ V[str(k)].conj().T) for k in range(num_users_sc)])))\n"
     ]
    }
   ],
   "source": [
    "V_init_dict = {}\n",
    "\n",
    "for idx, row in H.iterrows():\n",
    "    row = H.iloc[0]  # Get first row\n",
    "    H_dict = {str(i): row[i] for i in range(len(row))}\n",
    "    V_init = init_V(H_dict)\n",
    "    V_init_proj = proj_power(V_init, set_up.PT)\n",
    "    V_init_dict[str(idx)] = V_init_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ae86fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V = {}\n",
    "# d = set_up.d\n",
    "# for i in range(10):\n",
    "#     V[str(i)] = {}\n",
    "#     for j in range(set_up.K):\n",
    "#         V[str(i)][str(j)] = torch.randn(n_t, d[j], dtype=torch.cfloat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "354ab8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set_up = setup(n_tx=8, n_rx=[2, 2, 2, 2], num_streams=[2, 2, 2, 2], num_users=4, P=5)\n",
    "du = DUNN(num_layers=5, setup=set_up)\n",
    "\n",
    "tr = Trainer(model=du, setup=set_up, lr=1e-3)\n",
    "tr.train_epoch(H, loss_fn=sum_rate_loss_BC, num_epochs=10, batch_size=2, V_init = V_init_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep-Unfolding-NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
