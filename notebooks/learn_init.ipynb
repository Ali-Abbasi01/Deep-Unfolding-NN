{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f547db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "43de5e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alg_dual_link_torch(power_total: float, weight: torch.Tensor, H_links: torch.Tensor,\n",
    "                  rate_diff: float, Sigma=None, device=None):\n",
    "    \"\"\"\n",
    "    PyTorch version of dual-link algorithm\n",
    "    \n",
    "    Args:\n",
    "        power_total: Total power constraint\n",
    "        weight: Weight tensor of shape (n_links,)\n",
    "        H_links: Channel matrix tensor of shape (n_links, n_links, n_rx, n_tx)\n",
    "        rate_diff: Rate difference threshold for convergence\n",
    "        Sigma: Initial covariance matrices (optional)\n",
    "        device: Device to run computation on\n",
    "    \n",
    "    Returns:\n",
    "        sum_rate_list: List of sum rates per iteration\n",
    "        final_sum_rate: Final sum rate\n",
    "        rates: Individual link rates\n",
    "        Sigma: Final covariance matrices\n",
    "        Sigma_hat: Final dual covariance matrices\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = H_links.device\n",
    "    \n",
    "    # Move tensors to device\n",
    "    H_links = H_links.to(device)\n",
    "    weight = weight.to(device)\n",
    "    \n",
    "    #------------------------------------------------\n",
    "    # find basic parameters\n",
    "    #------------------------------------------------\n",
    "    n_links = H_links.shape[0]\n",
    "    rates = torch.zeros(n_links, device=device)\n",
    "    Sigma_hat = [None] * n_links\n",
    "    \n",
    "    #------------------------------------------------\n",
    "    # If initial Sigma not given, make it identity\n",
    "    #------------------------------------------------\n",
    "    if Sigma is None:\n",
    "        Sigma = [None] * n_links\n",
    "        for l_link in range(n_links):\n",
    "            lt_l = H_links[l_link, l_link].shape[1]\n",
    "            # power constraint may not be satisfied\n",
    "            Sigma[l_link] = (power_total / lt_l / n_links * \n",
    "                           torch.eye(lt_l, dtype=torch.complex64, device=device))\n",
    "    \n",
    "    #---------------------------------------------\n",
    "    # repeat until rate change is small\n",
    "    sum_rate_temp = torch.tensor(-float('inf'), device=device)\n",
    "    sum_rate_list = []\n",
    "    \n",
    "    num_epochs = 0\n",
    "    while num_epochs < 20:\n",
    "        num_epochs += 1\n",
    "        # calculate reverse link Sigma_hat's\n",
    "        power_normalizer = torch.tensor(0.0, device=device)\n",
    "        sum_rate = torch.tensor(0.0, device=device)\n",
    "        \n",
    "        for l_link in range(n_links):\n",
    "            # calculate forward link interference\n",
    "            total_Cov_l = torch.eye(H_links[l_link, l_link].shape[0], \n",
    "                                  dtype=torch.complex64, device=device)\n",
    "            \n",
    "            for k_link in range(n_links):\n",
    "                total_Cov_l += (H_links[l_link, k_link] @ Sigma[k_link] @ \n",
    "                              H_links[l_link, k_link].T.conj())\n",
    "            \n",
    "            Omega_l = (total_Cov_l - H_links[l_link, l_link] @ Sigma[l_link] @ \n",
    "                      H_links[l_link, l_link].T.conj())\n",
    "            \n",
    "            # -------------------------------------------------------------------\n",
    "            # calculate the rates using log determinant\n",
    "            hy = torch.logdet(total_Cov_l).real\n",
    "            hy_x = torch.logdet(Omega_l).real\n",
    "            rates[l_link] = hy - hy_x\n",
    "            # -------------------------------------------------------------------\n",
    "            sum_rate += weight[l_link] * rates[l_link]\n",
    "            \n",
    "            Sigma_hat[l_link] = weight[l_link] * (torch.linalg.inv(Omega_l) -\n",
    "                                                torch.linalg.inv(total_Cov_l))\n",
    "            power_normalizer += torch.trace(Sigma_hat[l_link]).real\n",
    "        \n",
    "        # -------------------------------------------------------------------\n",
    "        # break out of loop if rate change is small\n",
    "        sum_rate_list.append((sum_rate / torch.log(torch.tensor(2.0))).item())\n",
    "        \n",
    "        # if (sum_rate / torch.log(torch.tensor(2.0)) - \n",
    "        #     sum_rate_temp / torch.log(torch.tensor(2.0))) < rate_diff:\n",
    "        #     break\n",
    "        \n",
    "        # --------------------------------------------------------------------\n",
    "        sum_rate_temp = sum_rate\n",
    "        \n",
    "        # Normalize Sigma_hat\n",
    "        for l_link in range(n_links):\n",
    "            Sigma_hat[l_link] = Sigma_hat[l_link] * power_total / power_normalizer\n",
    "        \n",
    "        # --------------------------------------------------------------------\n",
    "        # calculate forward link Sigma's\n",
    "        # --------------------------------------------------------------------\n",
    "        power_normalizer = torch.tensor(0.0, device=device)\n",
    "        \n",
    "        for l_link in range(n_links):\n",
    "            # calculate forward link interference\n",
    "            total_Cov_hat_l = torch.eye(H_links[l_link, l_link].shape[1], \n",
    "                                      dtype=torch.complex64, device=device)\n",
    "            \n",
    "            for k_link in range(n_links):\n",
    "                total_Cov_hat_l += (H_links[k_link, l_link].T.conj() @ \n",
    "                                  Sigma_hat[k_link] @ H_links[k_link, l_link])\n",
    "            \n",
    "            Omega_hat_l = (total_Cov_hat_l - H_links[l_link, l_link].T.conj() @ \n",
    "                          Sigma_hat[l_link] @ H_links[l_link, l_link])\n",
    "            \n",
    "            Sigma[l_link] = weight[l_link] * (torch.linalg.inv(Omega_hat_l) -\n",
    "                                            torch.linalg.inv(total_Cov_hat_l))\n",
    "            power_normalizer += torch.trace(Sigma[l_link]).real\n",
    "        \n",
    "        # Normalize Sigma\n",
    "        for l_link in range(n_links):\n",
    "            Sigma[l_link] = Sigma[l_link] * power_total / power_normalizer\n",
    "    \n",
    "    return (sum_rate_list, \n",
    "            (sum_rate / torch.log(torch.tensor(2.0))),\n",
    "            (rates / torch.log(torch.tensor(2.0))),\n",
    "            Sigma, \n",
    "            Sigma_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7327dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelCNN(nn.Module):\n",
    "    def __init__(self, setup):\n",
    "        super(ChannelCNN, self).__init__()\n",
    "        self.L = setup.L            # number of outer and inner links (L x L)\n",
    "        self.n_rx = setup.n_rx      # receive antennas per channel matrix\n",
    "        self.n_tx = setup.n_tx      # transmit antennas\n",
    "        self.d = setup.d            # beamforming rank\n",
    "\n",
    "        in_channels = 2 * self.L * self.L  # real + imag for each of L x L complex matrices\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * self.n_rx * self.n_tx, 256)\n",
    "        self.fc2 = nn.Linear(256, 2 * self.L * self.n_tx * self.d)  # 2 (real+imag) x L x n_tx x d\n",
    "\n",
    "    def df_to_tensor(self, x_df):\n",
    "        \"\"\"\n",
    "        Input: DataFrame [B, L], where each cell is a list of L complex matrices [n_rx x n_tx]\n",
    "        Output: Tensor [B, 2*L*L, n_rx, n_tx]\n",
    "        \"\"\"\n",
    "        B = len(x_df)\n",
    "        L = self.L\n",
    "        N_r = self.n_rx\n",
    "        N_t = self.n_tx\n",
    "\n",
    "        real_parts = torch.empty((B, L, L, N_r, N_t))\n",
    "        imag_parts = torch.empty((B, L, L, N_r, N_t))\n",
    "\n",
    "        for i in range(B):\n",
    "            for l1 in range(L):\n",
    "                link_list = x_df.iloc[i, l1]  # list of L complex matrices\n",
    "                for l2 in range(L):\n",
    "                    H = link_list[l2]\n",
    "                    real_parts[i, l1, l2] = H.real\n",
    "                    imag_parts[i, l1, l2] = H.imag\n",
    "\n",
    "        # Reshape to [B, 2*L*L, n_rx, n_tx]\n",
    "        real_flat = real_parts.view(B, L * L, N_r, N_t)\n",
    "        imag_flat = imag_parts.view(B, L * L, N_r, N_t)\n",
    "        x_tensor = torch.cat([real_flat, imag_flat], dim=1)\n",
    "        return x_tensor\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # Reshape to [B, L, 2, n_tx, d]\n",
    "        B = x.size(0)\n",
    "        x = x.view(B, self.L, 2, self.n_tx, self.d)\n",
    "\n",
    "        real = x[:, :, 0, :, :]\n",
    "        imag = x[:, :, 1, :, :]\n",
    "        return torch.complex(real, imag)  # [B, L, n_tx, d]\n",
    "\n",
    "    def predict(self, x_df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Input: DataFrame of shape [B, L], where each cell contains a list of L complex matrices\n",
    "        Output: Dict[str][str] → maps sample and link index to complex beamforming matrix\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        x_tensor = self.df_to_tensor(x_df)\n",
    "        with torch.no_grad():\n",
    "            out = self.forward(x_tensor)  # [B, L, n_tx, d]\n",
    "\n",
    "        # Convert to nested dict\n",
    "        B = out.shape[0]\n",
    "        output_dict = {}\n",
    "        for i in range(B):\n",
    "            link_dict = {}\n",
    "            for l in range(self.L):\n",
    "                link_dict[str(l)] = out[i, l]  # [n_tx, d]\n",
    "            output_dict[str(i)] = link_dict\n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d726393",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelCNNTrainer():\n",
    "    def __init__(self, model: ChannelCNN, setup, lr=1e-3, lambda_power=1.0):\n",
    "        self.model = model\n",
    "        self.setup = setup\n",
    "        self.lambda_power = lambda_power\n",
    "        self.optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    def power_penalty(self, V_dict):\n",
    "        \"\"\"Compute penalty if Tr(V V†) > Pmax for any link.\"\"\"\n",
    "        penalty = 0.0\n",
    "        for sample in V_dict.values():\n",
    "            for V in sample.values():\n",
    "                power = torch.real(torch.trace(V @ V.conj().T))\n",
    "                overflow = torch.relu(power - self.setup.Pmax)\n",
    "                penalty += overflow\n",
    "        return penalty\n",
    "\n",
    "    def train(self, train_df, dual_link_fn, num_epochs=100, batch_size=16):\n",
    "        self.model.train()\n",
    "        num_samples = len(train_df)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_loss = 0.0\n",
    "            perm = torch.randperm(num_samples)\n",
    "\n",
    "            for i in range(0, num_samples, batch_size):\n",
    "                idx = perm[i:i + batch_size]\n",
    "                batch_df = train_df.iloc[idx]\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # Step 1: Predict initial beamforming V_init from CNN\n",
    "                V_init_dict = self.model.predict(batch_df)\n",
    "\n",
    "                # Step 2: Run dual-link to get final beamforming matrices\n",
    "                V_final_dict = dual_link_fn(V_init_dict, batch_df)\n",
    "\n",
    "                # Step 3: Compute loss\n",
    "                power_loss = self.power_penalty(V_final_dict)\n",
    "                sum_rate = self.compute_sum_rate(V_final_dict, batch_df)\n",
    "                loss = self.lambda_power * power_loss - sum_rate\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "            print(f\"Epoch {epoch + 1} | Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    def compute_sum_rate(self, V_dict, H_df):\n",
    "        \"\"\"Sum-rate computation: ∑ log det(I + HVV†H† / noise)\"\"\"\n",
    "        # Dummy version — you should replace with your system's real sum-rate calc\n",
    "        total = 0.0\n",
    "        for i in range(len(H_df)):\n",
    "            for l in range(self.setup.L):\n",
    "                H = H_df.iloc[i, l]  # channel matrix\n",
    "                V = V_dict[str(i)][str(l)]  # beamforming\n",
    "                signal = H @ V\n",
    "                power_matrix = signal @ signal.conj().T\n",
    "                rate = torch.logdet(torch.eye(power_matrix.shape[0]) + power_matrix).real\n",
    "                total += rate\n",
    "        return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3035f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_rate_loss(H, V, alpha, sig):\n",
    "    # Calculate sum rate for single cell\n",
    "    sum_rate = 0\n",
    "    for k in range(len(H)):\n",
    "        Nr = H[str(k)].shape[0]\n",
    "        # Calculate Omega\n",
    "        S = 0\n",
    "        for l in range(len(H)):\n",
    "            if l == k: pass\n",
    "            else:\n",
    "                S += H[str(k)] @ V[str(l)] @ V[str(l)].conj().T @ H[str(k)].conj().T\n",
    "        S += sig[k] * torch.eye(Nr, dtype=torch.cdouble)\n",
    "        tmp = torch.eye(Nr, dtype=torch.cdouble) + H[str(k)] @ V[str(k)] @ V[str(k)].conj().T @ H[str(k)].conj().T @ torch.linalg.inv(S)\n",
    "        R = torch.log2(torch.linalg.det(tmp))\n",
    "        sum_rate += alpha[k] * R\n",
    "    return sum_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99936cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelCNN(nn.Module):\n",
    "    def __init__(self, setup):\n",
    "        super(ChannelCNN, self).__init__()\n",
    "        self.L = setup.L\n",
    "        self.n_rx = setup.n_rx\n",
    "        self.n_tx = setup.n_tx\n",
    "        self.d = setup.d\n",
    "\n",
    "        in_channels = 2 * self.L * self.L\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * self.n_rx * self.n_tx, 256)\n",
    "        self.fc2 = nn.Linear(256, 2 * self.L * self.n_tx * self.d)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.conv2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # Reshape to [B, L, 2, n_tx, d]\n",
    "        B = x.size(0)\n",
    "        x = x.view(B, self.L, 2, self.n_tx, self.d)\n",
    "\n",
    "        real = x[:, :, 0, :, :]\n",
    "        imag = x[:, :, 1, :, :]\n",
    "        return torch.complex(real, imag)  # [B, L, n_tx, d]\n",
    "\n",
    "    def predict(self, x):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            out = self.forward(x)  # [B, L, n_tx, d]\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "class ChannelCNNTrainer():\n",
    "    def __init__(self, model: ChannelCNN, setup, lr=1e-3):\n",
    "        self.model = model\n",
    "        self.setup = setup\n",
    "        self.optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    def train(self, train_list, dual_link_fn, num_epochs=100, batch_size=2):\n",
    "        self.model.train()\n",
    "        num_samples = len(train_list)\n",
    "\n",
    "        def V_to_Sigma(V):\n",
    "            Sigma = torch.zeros_like(V)\n",
    "            for i in range(len(V)):\n",
    "                for j in range(self.setup.L):\n",
    "                    Sigma[i][j] = V[i, j] @ V[i, j].conj().T\n",
    "            return Sigma\n",
    "\n",
    "\n",
    "        def proj_power(Sigma):\n",
    "            for i in range(len(Sigma)):\n",
    "                s = 0\n",
    "                for j in range(self.setup.L):\n",
    "                    s += torch.trace(Sigma[i, j])\n",
    "                for j in range(self.setup.L):\n",
    "                    Sigma[i, j] = (self.setup.PT/s) * Sigma[i, j]\n",
    "            return Sigma\n",
    "        \n",
    "        def sum_rate_loss(Sigma, H_list):\n",
    "            total = 0\n",
    "            for i in range(len(H_list)):\n",
    "                s_rate = 0\n",
    "                for l in range(H_list[0].shape[0]):\n",
    "                    Omeg = 0\n",
    "                    for k in range(H_list[0].shape[0]):\n",
    "                        if k != l:\n",
    "                            Omeg += H_list[i][l, k] @ Sigma[k] @ H_list[i][l, k].conj().T\n",
    "                    Omeg = torch.eye(H_list[0].shape[2]) + Omeg\n",
    "                    rate = torch.log2(torch.linalg.det(torch.eye(H_list[0].shape[2]) + H_list[i][l, l] @ Sigma[l] @ H_list[i][l, l].conj().T @ torch.linalg.inv(Omeg)))\n",
    "                    s_rate += rate.real\n",
    "                total += s_rate\n",
    "            return total/len(H_list)\n",
    "        \n",
    "        def sep_real_imag(x):\n",
    "            real = x.real\n",
    "            imag = x.imag\n",
    "            B, L, _, n_rx, n_tx = real.shape\n",
    "            real = real.view(B, L * L, n_rx, n_tx)\n",
    "            imag = imag.view(B, L * L, n_rx, n_tx)\n",
    "            x_prepared = torch.cat([real, imag], dim=1)\n",
    "            return x_prepared\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_loss = 0.0\n",
    "            for i in range(0, num_samples, batch_size):\n",
    "                batch_list = train_list[i:i + batch_size]\n",
    "                batch_tensor = torch.stack(batch_list)\n",
    "                batch_tensor_sep = sep_real_imag(batch_tensor)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                V_init = self.model.forward(batch_tensor_sep)\n",
    "\n",
    "                Sigma_init = V_to_Sigma(V_init)\n",
    "\n",
    "                Sigma_proj = proj_power(Sigma_init)\n",
    "\n",
    "                Sigma_final_list = []\n",
    "\n",
    "                for j in range(len(Sigma_proj)):\n",
    "                    _, _, _, Sigma_final, _ = dual_link_fn(power_total=self.setup.PT, weight=torch.ones(self.setup.L), H_links=batch_tensor[j], rate_diff=.001, Sigma=Sigma_proj[j], device=None)\n",
    "\n",
    "                    Sigma_final_list.append(Sigma_final)\n",
    "\n",
    "                loss = sum_rate_loss(Sigma_final_list, batch_list)\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                self.optimizer.step()\n",
    "\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "            print(f\"Epoch {epoch + 1} | Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56e39015",
   "metadata": {},
   "outputs": [],
   "source": [
    "class setup():\n",
    "    def __init__(self, L, n_tx, n_rx, d, PT):\n",
    "        self.L = L\n",
    "        self.n_rx = n_rx\n",
    "        self.n_tx = n_tx\n",
    "        self.d = d\n",
    "        self.PT = PT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1728cdbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.3946+0.0486j,  0.7317+0.3820j],\n",
      "          [-0.1764-0.6837j, -0.6579+0.5496j]],\n",
      "\n",
      "         [[ 1.0405+0.7412j,  0.8382+0.1582j],\n",
      "          [ 1.2651-1.2669j,  0.0047-0.8160j]]],\n",
      "\n",
      "\n",
      "        [[[-0.7422-0.3130j,  0.6426+0.6178j],\n",
      "          [-0.8853+1.5156j,  0.1836-0.7439j]],\n",
      "\n",
      "         [[ 0.5190+0.5220j,  0.8251+1.7575j],\n",
      "          [-0.3020-0.4075j, -0.1992+1.0411j]]]])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m CHCNN \u001b[38;5;241m=\u001b[39m ChannelCNN(set_up)\n\u001b[1;32m      4\u001b[0m tr \u001b[38;5;241m=\u001b[39m ChannelCNNTrainer(CHCNN, set_up)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mH_l\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdual_link_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malg_dual_link_torch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[48], line 117\u001b[0m, in \u001b[0;36mChannelCNNTrainer.train\u001b[0;34m(self, train_list, dual_link_fn, num_epochs, batch_size)\u001b[0m\n\u001b[1;32m    113\u001b[0m     _, _, _, Sigma_final, _ \u001b[38;5;241m=\u001b[39m dual_link_fn(power_total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup\u001b[38;5;241m.\u001b[39mPT, weight\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup\u001b[38;5;241m.\u001b[39mL), H_links\u001b[38;5;241m=\u001b[39mbatch_tensor[j], rate_diff\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.001\u001b[39m, Sigma\u001b[38;5;241m=\u001b[39mSigma_proj[j], device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    115\u001b[0m     Sigma_final_list\u001b[38;5;241m.\u001b[39mappend(Sigma_final)\n\u001b[0;32m--> 117\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43msum_rate_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSigma_final_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[48], line 79\u001b[0m, in \u001b[0;36mChannelCNNTrainer.train.<locals>.sum_rate_loss\u001b[0;34m(Sigma, H_list)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m l:\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28mprint\u001b[39m(H_list[i])\n\u001b[0;32m---> 79\u001b[0m         Omeg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m H_list[i][l, k] \u001b[38;5;241m@\u001b[39m \u001b[43mSigma\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m@\u001b[39m H_list[i][l, k]\u001b[38;5;241m.\u001b[39mconj()\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     80\u001b[0m Omeg \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meye(H_list[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;241m+\u001b[39m Omeg\n\u001b[1;32m     81\u001b[0m rate \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog2(torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mdet(torch\u001b[38;5;241m.\u001b[39meye(H_list[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;241m+\u001b[39m H_list[i][l, l] \u001b[38;5;241m@\u001b[39m Sigma[l] \u001b[38;5;241m@\u001b[39m H_list[i][l, l]\u001b[38;5;241m.\u001b[39mconj()\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39minv(Omeg)))\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "set_up = setup(2, 2, 2, 2, 10)\n",
    "H_l = [torch.randn(2, 2, 2, 2, dtype=torch.cfloat) for _ in range(1)]\n",
    "CHCNN = ChannelCNN(set_up)\n",
    "tr = ChannelCNNTrainer(CHCNN, set_up)\n",
    "tr.train(train_list=H_l, dual_link_fn=alg_dual_link_torch, num_epochs=100, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c868ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[-0.4214+0.2341j, -0.7542-0.9747j],\n",
       "          [-0.2162-0.5214j, -0.4185+0.0505j]],\n",
       " \n",
       "         [[-0.3557-0.3714j,  0.4628-1.7675j],\n",
       "          [-0.2169+1.1543j,  1.0290+0.3764j]]], dtype=torch.complex128)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3489b1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.4214+0.2341j, -0.7542-0.9747j],\n",
       "          [-0.2162-0.5214j, -0.4185+0.0505j]],\n",
       "\n",
       "         [[-0.3557-0.3714j,  0.4628-1.7675j],\n",
       "          [-0.2169+1.1543j,  1.0290+0.3764j]]]], dtype=torch.complex128)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(H_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304fe10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_real_imag(x):\n",
    "    real = x.real\n",
    "    imag = x.imag\n",
    "    B, L, _, n_rx, n_tx = real.shape\n",
    "    real = real.view(B, L * L, n_rx, n_tx)\n",
    "    imag = imag.view(B, L * L, n_rx, n_tx)\n",
    "    x_prepared = torch.cat([real, imag], dim=1)\n",
    "    return x_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35651cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[-0.8338+1.0405e+00j,  0.4757+3.4996e-01j],\n",
       "           [-0.0303+4.2392e-02j,  0.1230-1.2014e+00j],\n",
       "           [ 0.3458+5.6647e-01j, -0.4790+4.3923e-02j],\n",
       "           [-0.5486+4.2100e-01j,  0.1023-4.6791e-01j]],\n",
       "\n",
       "          [[-0.2507-2.4065e-01j,  0.3092-1.5110e-01j],\n",
       "           [-1.1487-3.9568e-01j,  0.9772-1.1364e-01j],\n",
       "           [-0.9313-2.0152e+00j,  0.5331-3.6845e-01j],\n",
       "           [-0.3436+5.6671e-01j,  0.0743+1.4087e-01j]],\n",
       "\n",
       "          [[ 0.2113+1.0401e-01j,  0.2039-1.6424e-02j],\n",
       "           [ 0.3469+7.0318e-01j, -0.6420+2.9779e-03j],\n",
       "           [-0.5378-1.5603e+00j, -0.6760+7.2648e-01j],\n",
       "           [-0.7727+2.3655e-01j,  0.3408-7.9605e-01j]]],\n",
       "\n",
       "\n",
       "         [[[-0.2264+2.4068e-01j, -1.1467+1.3749e+00j],\n",
       "           [-0.3290+1.1172e+00j, -1.2517+6.2754e-01j],\n",
       "           [-1.0357-2.3168e-01j, -0.3360+1.9195e-02j],\n",
       "           [-0.4317-6.3169e-01j,  0.0816-1.5335e-01j]],\n",
       "\n",
       "          [[ 0.8999+4.8393e-01j, -0.4039+8.9042e-01j],\n",
       "           [ 0.1793+2.2209e-01j, -0.0104+1.8233e+00j],\n",
       "           [-0.0118-1.5219e-01j, -1.0850+2.7973e-01j],\n",
       "           [-0.7602-3.8913e-01j, -0.0546-9.1316e-01j]],\n",
       "\n",
       "          [[ 0.7685-6.5165e-02j, -0.5421-2.1077e-01j],\n",
       "           [-0.6928+4.8477e-01j, -0.7627-2.8155e-01j],\n",
       "           [ 0.1184+8.5091e-01j,  0.0558+4.9693e-01j],\n",
       "           [ 0.6783-1.2386e+00j,  0.5740-5.9692e-02j]]],\n",
       "\n",
       "\n",
       "         [[[ 1.2757+5.8220e-01j, -0.9850+1.8472e-01j],\n",
       "           [-0.8896-9.7723e-01j,  0.0410+7.8902e-01j],\n",
       "           [ 0.1519+7.0570e-01j,  0.2206+2.5421e-01j],\n",
       "           [-0.9217+1.8808e-01j, -0.2201-9.4834e-02j]],\n",
       "\n",
       "          [[ 0.0348-1.2258e-01j,  0.8953-8.3815e-01j],\n",
       "           [ 1.1500+5.6458e-01j, -1.0916-1.2395e+00j],\n",
       "           [ 0.0498+3.7978e-01j, -0.5269-1.1653e+00j],\n",
       "           [ 0.1540-3.0695e-01j,  0.3480-1.2585e-02j]],\n",
       "\n",
       "          [[ 1.1502+3.1006e-01j, -0.1617-1.6512e-01j],\n",
       "           [-0.1146-7.8851e-01j, -0.0935+1.4278e+00j],\n",
       "           [ 0.7753-5.5110e-01j, -0.5553+4.2796e-01j],\n",
       "           [ 1.1275-7.7055e-01j, -0.8822+1.7577e+00j]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[-0.0130-5.2109e-01j, -1.0877-3.6624e-01j],\n",
       "           [-1.3165-2.7252e-01j,  0.3392-1.5179e-01j],\n",
       "           [ 0.2214+5.3541e-01j,  0.8723-1.4925e+00j],\n",
       "           [-0.2840-5.1553e-01j, -0.0061-1.6492e-01j]],\n",
       "\n",
       "          [[ 0.2953+1.3891e-01j, -0.4544+4.6719e-01j],\n",
       "           [-1.1855-1.9275e-01j,  0.2239+3.1100e-02j],\n",
       "           [ 0.3212-2.5924e-01j,  0.2014-4.9191e-01j],\n",
       "           [ 0.6607+1.8156e+00j,  0.3241-2.9185e-01j]],\n",
       "\n",
       "          [[-0.9889-1.7933e-02j,  1.1705+3.4638e-01j],\n",
       "           [ 0.1109-9.5039e-02j,  0.3913-1.2917e-01j],\n",
       "           [ 0.3502-6.2345e-01j,  0.1996+1.0841e-01j],\n",
       "           [-0.0312-2.9490e-01j,  0.0673-9.3095e-01j]]],\n",
       "\n",
       "\n",
       "         [[[ 0.6567+6.0772e-01j,  0.4715-7.2148e-01j],\n",
       "           [ 0.4862+5.8367e-01j,  0.7831-7.6984e-04j],\n",
       "           [-1.0426-1.1978e+00j,  0.6589+9.7273e-01j],\n",
       "           [-0.0732+8.4603e-01j, -0.4121-2.3220e-01j]],\n",
       "\n",
       "          [[ 0.4100-5.9015e-02j,  0.7845-1.4996e-01j],\n",
       "           [-0.3187-4.0785e-01j, -0.8017+8.8541e-01j],\n",
       "           [-0.4489+3.5530e-01j,  0.4301-1.7748e-01j],\n",
       "           [ 1.4372+6.9630e-01j,  0.2688+2.7531e-01j]],\n",
       "\n",
       "          [[ 0.4770-2.7700e-01j, -0.0281-1.0112e-01j],\n",
       "           [-0.6477+9.2382e-01j, -0.1503-8.8097e-01j],\n",
       "           [ 0.3876+2.4920e-01j,  1.0186+4.1751e-01j],\n",
       "           [ 1.2080-5.7088e-01j, -0.4110+6.6312e-02j]]],\n",
       "\n",
       "\n",
       "         [[[ 0.8031-7.5698e-01j, -0.9016-6.5306e-01j],\n",
       "           [ 0.3788+7.4474e-02j,  0.5211-3.4682e-02j],\n",
       "           [ 0.0983-2.9531e-01j,  0.0030-3.5566e-01j],\n",
       "           [-0.3359-2.6982e-01j, -0.6430-2.7225e-02j]],\n",
       "\n",
       "          [[-0.1612+5.5157e-01j,  1.2133-6.8365e-01j],\n",
       "           [ 0.6726+6.4426e-01j, -0.9784+1.1381e+00j],\n",
       "           [ 0.6986-9.8268e-01j,  0.3210-5.4101e-01j],\n",
       "           [ 0.2484-2.9512e-01j, -0.9039+4.1538e-01j]],\n",
       "\n",
       "          [[ 0.1406+2.2576e-01j, -0.9934-1.2995e-02j],\n",
       "           [-0.6810-3.9881e-01j,  0.6967+4.4925e-02j],\n",
       "           [ 0.0300+1.1994e+00j, -0.4750+2.9329e-01j],\n",
       "           [ 0.0358-1.3741e-01j, -0.3241+1.6450e+00j]]]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 3, 4, 2, dtype=torch.complex64)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9075455f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-8.3385e-01,  4.7575e-01],\n",
       "          [-3.0258e-02,  1.2301e-01],\n",
       "          [ 3.4576e-01, -4.7901e-01],\n",
       "          [-5.4856e-01,  1.0233e-01]],\n",
       "\n",
       "         [[-2.5067e-01,  3.0921e-01],\n",
       "          [-1.1487e+00,  9.7721e-01],\n",
       "          [-9.3128e-01,  5.3308e-01],\n",
       "          [-3.4357e-01,  7.4333e-02]],\n",
       "\n",
       "         [[ 2.1133e-01,  2.0391e-01],\n",
       "          [ 3.4690e-01, -6.4199e-01],\n",
       "          [-5.3777e-01, -6.7599e-01],\n",
       "          [-7.7272e-01,  3.4079e-01]],\n",
       "\n",
       "         [[-2.2641e-01, -1.1467e+00],\n",
       "          [-3.2902e-01, -1.2517e+00],\n",
       "          [-1.0357e+00, -3.3601e-01],\n",
       "          [-4.3171e-01,  8.1640e-02]],\n",
       "\n",
       "         [[ 8.9993e-01, -4.0392e-01],\n",
       "          [ 1.7927e-01, -1.0412e-02],\n",
       "          [-1.1773e-02, -1.0850e+00],\n",
       "          [-7.6020e-01, -5.4563e-02]],\n",
       "\n",
       "         [[ 7.6847e-01, -5.4209e-01],\n",
       "          [-6.9276e-01, -7.6274e-01],\n",
       "          [ 1.1837e-01,  5.5798e-02],\n",
       "          [ 6.7826e-01,  5.7400e-01]],\n",
       "\n",
       "         [[ 1.2757e+00, -9.8498e-01],\n",
       "          [-8.8962e-01,  4.0953e-02],\n",
       "          [ 1.5189e-01,  2.2061e-01],\n",
       "          [-9.2169e-01, -2.2011e-01]],\n",
       "\n",
       "         [[ 3.4760e-02,  8.9529e-01],\n",
       "          [ 1.1500e+00, -1.0916e+00],\n",
       "          [ 4.9827e-02, -5.2692e-01],\n",
       "          [ 1.5404e-01,  3.4799e-01]],\n",
       "\n",
       "         [[ 1.1502e+00, -1.6166e-01],\n",
       "          [-1.1455e-01, -9.3456e-02],\n",
       "          [ 7.7529e-01, -5.5534e-01],\n",
       "          [ 1.1275e+00, -8.8215e-01]],\n",
       "\n",
       "         [[ 1.0405e+00,  3.4996e-01],\n",
       "          [ 4.2392e-02, -1.2014e+00],\n",
       "          [ 5.6647e-01,  4.3923e-02],\n",
       "          [ 4.2100e-01, -4.6791e-01]],\n",
       "\n",
       "         [[-2.4065e-01, -1.5110e-01],\n",
       "          [-3.9568e-01, -1.1364e-01],\n",
       "          [-2.0152e+00, -3.6845e-01],\n",
       "          [ 5.6671e-01,  1.4087e-01]],\n",
       "\n",
       "         [[ 1.0401e-01, -1.6424e-02],\n",
       "          [ 7.0318e-01,  2.9779e-03],\n",
       "          [-1.5603e+00,  7.2648e-01],\n",
       "          [ 2.3655e-01, -7.9605e-01]],\n",
       "\n",
       "         [[ 2.4068e-01,  1.3749e+00],\n",
       "          [ 1.1172e+00,  6.2754e-01],\n",
       "          [-2.3168e-01,  1.9195e-02],\n",
       "          [-6.3169e-01, -1.5335e-01]],\n",
       "\n",
       "         [[ 4.8393e-01,  8.9042e-01],\n",
       "          [ 2.2209e-01,  1.8233e+00],\n",
       "          [-1.5219e-01,  2.7973e-01],\n",
       "          [-3.8913e-01, -9.1316e-01]],\n",
       "\n",
       "         [[-6.5165e-02, -2.1077e-01],\n",
       "          [ 4.8477e-01, -2.8155e-01],\n",
       "          [ 8.5091e-01,  4.9693e-01],\n",
       "          [-1.2386e+00, -5.9692e-02]],\n",
       "\n",
       "         [[ 5.8220e-01,  1.8472e-01],\n",
       "          [-9.7723e-01,  7.8902e-01],\n",
       "          [ 7.0570e-01,  2.5421e-01],\n",
       "          [ 1.8808e-01, -9.4834e-02]],\n",
       "\n",
       "         [[-1.2258e-01, -8.3815e-01],\n",
       "          [ 5.6458e-01, -1.2395e+00],\n",
       "          [ 3.7978e-01, -1.1653e+00],\n",
       "          [-3.0695e-01, -1.2585e-02]],\n",
       "\n",
       "         [[ 3.1006e-01, -1.6512e-01],\n",
       "          [-7.8851e-01,  1.4278e+00],\n",
       "          [-5.5110e-01,  4.2796e-01],\n",
       "          [-7.7055e-01,  1.7577e+00]]],\n",
       "\n",
       "\n",
       "        [[[-1.2983e-02, -1.0877e+00],\n",
       "          [-1.3165e+00,  3.3922e-01],\n",
       "          [ 2.2139e-01,  8.7229e-01],\n",
       "          [-2.8404e-01, -6.0589e-03]],\n",
       "\n",
       "         [[ 2.9533e-01, -4.5440e-01],\n",
       "          [-1.1855e+00,  2.2395e-01],\n",
       "          [ 3.2119e-01,  2.0137e-01],\n",
       "          [ 6.6075e-01,  3.2410e-01]],\n",
       "\n",
       "         [[-9.8888e-01,  1.1705e+00],\n",
       "          [ 1.1090e-01,  3.9130e-01],\n",
       "          [ 3.5018e-01,  1.9961e-01],\n",
       "          [-3.1159e-02,  6.7269e-02]],\n",
       "\n",
       "         [[ 6.5666e-01,  4.7153e-01],\n",
       "          [ 4.8621e-01,  7.8313e-01],\n",
       "          [-1.0426e+00,  6.5891e-01],\n",
       "          [-7.3187e-02, -4.1208e-01]],\n",
       "\n",
       "         [[ 4.0998e-01,  7.8446e-01],\n",
       "          [-3.1867e-01, -8.0167e-01],\n",
       "          [-4.4885e-01,  4.3013e-01],\n",
       "          [ 1.4372e+00,  2.6880e-01]],\n",
       "\n",
       "         [[ 4.7703e-01, -2.8092e-02],\n",
       "          [-6.4768e-01, -1.5030e-01],\n",
       "          [ 3.8762e-01,  1.0186e+00],\n",
       "          [ 1.2080e+00, -4.1103e-01]],\n",
       "\n",
       "         [[ 8.0307e-01, -9.0162e-01],\n",
       "          [ 3.7881e-01,  5.2107e-01],\n",
       "          [ 9.8269e-02,  2.9600e-03],\n",
       "          [-3.3592e-01, -6.4300e-01]],\n",
       "\n",
       "         [[-1.6120e-01,  1.2133e+00],\n",
       "          [ 6.7256e-01, -9.7844e-01],\n",
       "          [ 6.9861e-01,  3.2103e-01],\n",
       "          [ 2.4840e-01, -9.0391e-01]],\n",
       "\n",
       "         [[ 1.4057e-01, -9.9340e-01],\n",
       "          [-6.8104e-01,  6.9674e-01],\n",
       "          [ 2.9965e-02, -4.7505e-01],\n",
       "          [ 3.5761e-02, -3.2408e-01]],\n",
       "\n",
       "         [[-5.2109e-01, -3.6624e-01],\n",
       "          [-2.7252e-01, -1.5179e-01],\n",
       "          [ 5.3541e-01, -1.4925e+00],\n",
       "          [-5.1553e-01, -1.6492e-01]],\n",
       "\n",
       "         [[ 1.3891e-01,  4.6719e-01],\n",
       "          [-1.9275e-01,  3.1100e-02],\n",
       "          [-2.5924e-01, -4.9191e-01],\n",
       "          [ 1.8156e+00, -2.9185e-01]],\n",
       "\n",
       "         [[-1.7933e-02,  3.4638e-01],\n",
       "          [-9.5039e-02, -1.2917e-01],\n",
       "          [-6.2345e-01,  1.0841e-01],\n",
       "          [-2.9490e-01, -9.3095e-01]],\n",
       "\n",
       "         [[ 6.0772e-01, -7.2148e-01],\n",
       "          [ 5.8367e-01, -7.6984e-04],\n",
       "          [-1.1978e+00,  9.7273e-01],\n",
       "          [ 8.4603e-01, -2.3220e-01]],\n",
       "\n",
       "         [[-5.9015e-02, -1.4996e-01],\n",
       "          [-4.0785e-01,  8.8541e-01],\n",
       "          [ 3.5530e-01, -1.7748e-01],\n",
       "          [ 6.9630e-01,  2.7531e-01]],\n",
       "\n",
       "         [[-2.7700e-01, -1.0112e-01],\n",
       "          [ 9.2382e-01, -8.8097e-01],\n",
       "          [ 2.4920e-01,  4.1751e-01],\n",
       "          [-5.7088e-01,  6.6312e-02]],\n",
       "\n",
       "         [[-7.5698e-01, -6.5306e-01],\n",
       "          [ 7.4474e-02, -3.4682e-02],\n",
       "          [-2.9531e-01, -3.5566e-01],\n",
       "          [-2.6982e-01, -2.7225e-02]],\n",
       "\n",
       "         [[ 5.5157e-01, -6.8365e-01],\n",
       "          [ 6.4426e-01,  1.1381e+00],\n",
       "          [-9.8268e-01, -5.4101e-01],\n",
       "          [-2.9512e-01,  4.1538e-01]],\n",
       "\n",
       "         [[ 2.2576e-01, -1.2995e-02],\n",
       "          [-3.9881e-01,  4.4925e-02],\n",
       "          [ 1.1994e+00,  2.9329e-01],\n",
       "          [-1.3741e-01,  1.6450e+00]]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_prepared = sep_real_imag(x)\n",
    "x_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7324922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.5378-0.0980j, dtype=torch.complex128)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_list = [torch.randn(5, 5, 3, 2, dtype=torch.cdouble) for _ in range(10)]\n",
    "Sigma = torch.randn(5, 2, 2, dtype=torch.cdouble)\n",
    "sum_rate_loss(Sigma, H_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2242443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "\n",
    "def f(x):\n",
    "    z = x**2\n",
    "    return z\n",
    "\n",
    "y = f(x)\n",
    "\n",
    "y.backward()\n",
    "\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8bd3e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(torch.randn(2, 3, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep-Unfolding-NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
