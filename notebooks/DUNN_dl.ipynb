{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15938bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "#  Deep-Unfolded Dual-Link Network with\n",
    "#   • CNN initialiser (learns Σ(0))\n",
    "#   • GRU inverse controller  (learns X,Y,α per layer)\n",
    "#   • XA+Y inverse surrogate\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Dict, List\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "#  Problem \"setup\" helper (antennas, users, power, etc.)\n",
    "# ---------------------------------------------------------------------\n",
    "class Setup:\n",
    "    def __init__(self,\n",
    "                 n_tx: int,\n",
    "                 n_rx: int,\n",
    "                 K: int,\n",
    "                 streams: int,\n",
    "                 P_T: float):\n",
    "        self.n_tx  = n_tx          # BS antennas\n",
    "        self.n_rx  = n_rx          # antennas per UE (assume same for all)\n",
    "        self.K     = K             # number of users\n",
    "        self.d     = streams       # streams/user (assume same)\n",
    "        self.P_T   = P_T           # total power budget\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "#  1)  CNN initialiser  H -> Σ(0)\n",
    "# ---------------------------------------------------------------------\n",
    "class InitCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Very small CNN that treats each user identically.\n",
    "    Input   : real-imag stacked H in shape [B, 2, K, n_rx, n_tx]\n",
    "    Output  : Σ0        in shape [B, K, n_tx, d]\n",
    "              (we output beamformers; you may prefer covariances)\n",
    "    \"\"\"\n",
    "    def __init__(self, setup: Setup, hidden=32):\n",
    "        super().__init__()\n",
    "        self.setup = setup\n",
    "        c, k, r, t = 2, setup.K, setup.n_rx, setup.n_tx\n",
    "        self.conv1 = nn.Conv3d(c, hidden, kernel_size=1)\n",
    "        self.conv2 = nn.Conv3d(hidden, hidden, kernel_size=1)\n",
    "        self.relu  = nn.ReLU()\n",
    "        # final projection to (n_tx × d) per user\n",
    "        self.out   = nn.Linear(hidden, setup.n_tx * setup.d)\n",
    "\n",
    "    def forward(self, H_real_imag):              # [B, 2, K, n_rx, n_tx]\n",
    "        x = self.relu(self.conv1(H_real_imag))   # [B, h, K, r, t]\n",
    "        x = self.relu(self.conv2(x))             # same\n",
    "        x = x.mean(dim=[3,4])                    # global pool → [B, h, K]\n",
    "        x = x.transpose(1,2)                     # [B, K, h]\n",
    "        out = self.out(x)                        # [B, K, n_tx*d]\n",
    "        return out.view(-1, self.setup.K,\n",
    "                        self.setup.n_tx, self.setup.d)  # Σ0 (beamformers)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "#  2) GRU-based inverse controller   (shared across layers)\n",
    "# ---------------------------------------------------------------------\n",
    "class GRUInverseCell(nn.Module):\n",
    "    \"\"\"\n",
    "    Takes   : diagonal of A (shape [B, K, n_rx])  -- per user\n",
    "              hidden state  h  (shape [B, hidden])\n",
    "    Produces: X_diag (B,K,n_rx)   -- we keep X diag for cheap mult\n",
    "              Y_diag (B,K,n_rx)\n",
    "              alpha   (B,1,1,1)   -- damping coefficient\n",
    "              h_next\n",
    "    \"\"\"\n",
    "    def __init__(self, setup: Setup, hidden=64):\n",
    "        super().__init__()\n",
    "        self.setup = setup\n",
    "        self.hidden = hidden\n",
    "        self.gru   = nn.GRUCell(setup.K * setup.n_rx, hidden)\n",
    "        self.to_xy = nn.Linear(hidden, 2 * setup.K * setup.n_rx)\n",
    "        self.to_a  = nn.Linear(hidden, 1)\n",
    "\n",
    "    def forward(self, A_diag, h):\n",
    "        B, K, n = A_diag.shape\n",
    "        flat = A_diag.reshape(B, -1)              # [B, K*n]\n",
    "        h_next = self.gru(flat, h)                # [B, hidden]\n",
    "\n",
    "        xy = self.to_xy(h_next)                   # [B, 2*K*n]\n",
    "        xy = xy.view(B, 2, K, n)                  # [B, 2, K, n]\n",
    "        X_d, Y_d = xy[:,0], xy[:,1]               # each [B,K,n]\n",
    "        alpha = torch.sigmoid(self.to_a(h_next))  # (B,1) in (0,1)\n",
    "        alpha = alpha.view(B,1,1,1)\n",
    "        return X_d, Y_d, alpha, h_next\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "#  Helper: normalise power across all users\n",
    "# ---------------------------------------------------------------------\n",
    "def project_total_power(V, setup: Setup):\n",
    "    \"\"\"\n",
    "    V : [B, K, n_tx, d]\n",
    "    Scales each sample to meet ∑_k tr(V_k V_k^H)=P_T\n",
    "    \"\"\"\n",
    "    power = (V.conj().transpose(-1,-2) @ V).real.sum([-1,-2,-3])\n",
    "    scale = torch.sqrt(setup.P_T / power).view(-1,1,1,1)\n",
    "    return V * scale\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "#  3) One unfolded Dual-Link layer\n",
    "# ---------------------------------------------------------------------\n",
    "class DLLayer(nn.Module):\n",
    "    def __init__(self, setup: Setup, hidden=64):\n",
    "        super().__init__()\n",
    "        self.setup = setup\n",
    "        self.inv_cell = GRUInverseCell(setup, hidden)\n",
    "\n",
    "    # ---------------- core DL math helpers ----------------------------\n",
    "    def forward(self, V, H, h):\n",
    "        \"\"\"\n",
    "        V: [B,K,n_tx,d]  current beamformers  (Σ in DL pseudocode)\n",
    "        H: [B,K,n_rx,n_tx] channel per user (complex)\n",
    "        h: [B,hidden]     GRU hidden state\n",
    "        \"\"\"\n",
    "        B, K, n_tx, d = V.shape\n",
    "        n_rx = self.setup.n_rx\n",
    "\n",
    "        # -----  build A_l = I + Σ_{k≠l} H_lk Σ_k Σ_k^H H_lk^H ----------\n",
    "        # compute Σ_k Σ_k^H once\n",
    "        VVh = V @ V.conj().transpose(-1,-2)       # [B,K,n_tx,n_tx]\n",
    "\n",
    "        A_diag = []\n",
    "        for l in range(K):\n",
    "            s = VVh.sum(1) - VVh[:,l]             # Σ_k≠l ...\n",
    "            A_l = torch.eye(n_rx, device=H.device,\n",
    "                            dtype=H.dtype).expand(B,n_rx,n_rx) + \\\n",
    "                  (H[:,l] @ s @ H[:,l].conj().transpose(-1,-2))\n",
    "            if l==0:\n",
    "                A_stack = A_l.unsqueeze(1)\n",
    "            else:\n",
    "                A_stack = torch.cat([A_stack, A_l.unsqueeze(1)], dim=1)\n",
    "            A_diag.append(A_l.diagonal(dim1=-2, dim2=-1))  # [B,n_rx]\n",
    "        A_diag = torch.stack(A_diag, dim=1)        # [B,K,n_rx]\n",
    "\n",
    "        # -----  inverse surrogate via GRU cell -------------------------\n",
    "        X_d, Y_d, alpha, h_next = self.inv_cell(A_diag.real, h)  # ← GRU works on reals\n",
    "\n",
    "        # Build X and Y as diagonal matrices\n",
    "        X = torch.zeros_like(A_stack)\n",
    "        Y = torch.zeros_like(A_stack)\n",
    "        for l in range(K):\n",
    "            X[:,l].diagonal(dim1=-2, dim2=-1).copy_(X_d[:,l])\n",
    "            Y[:,l].diagonal(dim1=-2, dim2=-1).copy_(Y_d[:,l])\n",
    "\n",
    "        A_inv_hat = X @ A_stack + Y               # [B,K,n_rx,n_rx]\n",
    "\n",
    "        # -----  DL receiver & weight update (lines 5-7) ----------------\n",
    "        U = torch.einsum('bknm,bmtd->bknd', A_inv_hat, H.conj()) @ V\n",
    "        E = torch.eye(d, device=H.device, dtype=H.dtype) - \\\n",
    "            torch.einsum('bkdn,bknm,bmtd->bkdt', U.conj(), H, V)\n",
    "        # use diagonal surrogate for W (could reuse GRU)\n",
    "        diag_E_inv = 1 / E.diagonal(dim1=-2, dim2=-1)\n",
    "        W = torch.zeros_like(E)\n",
    "        for l in range(K):\n",
    "            W[:,l].diagonal(dim1=-2, dim2=-1).copy_(diag_E_inv[:,l])\n",
    "\n",
    "        # -----  Build B = I + Σ_k H_k^H U_k W_k U_k^H H_k  ------------\n",
    "        UWU = U @ W @ U.conj().transpose(-1,-2)   # [B,K,n_rx,n_rx]\n",
    "        B_mat = torch.eye(n_tx, device=H.device,\n",
    "                          dtype=H.dtype).expand(B,n_tx,n_tx) + \\\n",
    "                (H.conj().transpose(-1,-2) @ UWU @ H).sum(1)\n",
    "\n",
    "        # -----  Inverse of B via the *same* surrogate ------------------\n",
    "        B_diag = B_mat.diagonal(dim1=-2, dim2=-1)\n",
    "        Xb_d, Yb_d, _, _ = self.inv_cell(B_diag.real, h)  # reuse weights, no grad through alpha\n",
    "        Xb = torch.zeros_like(B_mat)\n",
    "        Yb = torch.zeros_like(B_mat)\n",
    "        Xb.diagonal(dim1=-2, dim2=-1).copy_(Xb_d[:,0])\n",
    "        Yb.diagonal(dim1=-2, dim2=-1).copy_(Yb_d[:,0])\n",
    "        B_inv_hat = Xb @ B_mat + Yb\n",
    "\n",
    "        # ----- new beamformers  (line 8) + damping ---------------------\n",
    "        V_new = torch.einsum('bnm,bmd->bnd', B_inv_hat,\n",
    "                 (H.conj().transpose(-1,-2) @ U @ W).sum(1)\n",
    "                 ).view(B,1,n_tx,d).repeat(1,K,1,1)\n",
    "\n",
    "        V = alpha * V_new + (1-alpha) * V         # recurrence / damping\n",
    "        V = project_total_power(V, self.setup)\n",
    "        return V, h_next\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "#  4) Full deep-unfolded network (L layers)\n",
    "# ---------------------------------------------------------------------\n",
    "class DLNet(nn.Module):\n",
    "    def __init__(self, setup: Setup,\n",
    "                 num_layers: int = 6,\n",
    "                 hidden: int = 64):\n",
    "        super().__init__()\n",
    "        self.setup     = setup\n",
    "        self.init_cnn  = InitCNN(setup)\n",
    "        self.layers    = nn.ModuleList(\n",
    "            [DLLayer(setup, hidden) for _ in range(num_layers)]\n",
    "        )\n",
    "        self.hidden_dim = hidden\n",
    "\n",
    "    def forward(self, H):\n",
    "        \"\"\"\n",
    "        H : complex tensor [B,K,n_rx,n_tx]\n",
    "        \"\"\"\n",
    "        B = H.size(0)\n",
    "        # stack real & imag for CNN\n",
    "        H_ri = torch.stack([H.real, H.imag], dim=1)  # [B,2,K,n_rx,n_tx]\n",
    "\n",
    "        V = self.init_cnn(H_ri).to(H.dtype)          # Σ(0)\n",
    "        V = project_total_power(V, self.setup)\n",
    "\n",
    "        h = torch.zeros(B, self.hidden_dim, device=H.device)\n",
    "        for layer in self.layers:\n",
    "            V, h = layer(V, H, h)\n",
    "        return V\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "#  Loss functions\n",
    "# ---------------------------------------------------------------------\n",
    "def sum_rate_loss(H, V, setup: Setup):\n",
    "    \"\"\"\n",
    "    Negative weighted sum-rate.\n",
    "    H: [B,K,n_rx,n_tx]   V: [B,K,n_tx,d]\n",
    "    \"\"\"\n",
    "    B,K,n_rx,n_tx = H.shape\n",
    "    d = setup.d\n",
    "    I = torch.eye(n_rx, device=H.device, dtype=H.dtype)\n",
    "\n",
    "    rate = 0.\n",
    "    for l in range(K):\n",
    "        HlVl = H[:,l] @ V[:,l]                     # [B,n_rx,d]\n",
    "        Sig_l = HlVl @ HlVl.conj().transpose(-1,-2)\n",
    "        noise = I\n",
    "        for k in range(K):\n",
    "            if k != l:\n",
    "                HkVk = H[:,l] @ V[:,k]\n",
    "                noise = noise + HkVk @ HkVk.conj().transpose(-1,-2)\n",
    "        SINR = noise.linalg.solve(Sig_l)           # (noise⁻¹ Sig)\n",
    "        rate += torch.logdet(I + SINR).real\n",
    "    return -rate.mean()\n",
    "\n",
    "\n",
    "def inversion_loss(A_inv, A):\n",
    "    return ((A_inv @ A -\n",
    "             torch.eye(A.size(-1),\n",
    "                       device=A.device,\n",
    "                       dtype=A.dtype)\n",
    "            )**2).sum(dim=[-2,-1]).mean()\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "#  Example training loop\n",
    "# ---------------------------------------------------------------------\n",
    "def train(model: DLNet,\n",
    "          loader: DataLoader,\n",
    "          setup: Setup,\n",
    "          epochs_warmup=2,\n",
    "          epochs_main=8,\n",
    "          lr=3e-4):\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs_warmup+epochs_main):\n",
    "        for H_batch in loader:\n",
    "            H_batch = H_batch.to(torch.complex64)\n",
    "            opt.zero_grad()\n",
    "            V_pred = model(H_batch)\n",
    "\n",
    "            loss = sum_rate_loss(H_batch, V_pred, setup)\n",
    "            # you can add a small inversion regulariser if unstable\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        phase = \"warm-up\" if epoch<epochs_warmup else \"main\"\n",
    "        print(f\"Epoch {epoch:02d} ({phase})  loss = {loss.item():.4f}\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "#  Usage example (dummy data)\n",
    "# ---------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    setup = Setup(n_tx=8, n_rx=2, K=4, streams=2, P_T=1.0)\n",
    "    B = 128                                    # batch-size for toy data\n",
    "    H_fake = (torch.randn(B,setup.K,setup.n_rx,setup.n_tx) +\n",
    "              1j*torch.randn(B,setup.K,setup.n_rx,setup.n_tx)) / 3**0.5\n",
    "\n",
    "    dataset = TensorDataset(H_fake)\n",
    "    loader  = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    net = DLNet(setup, num_layers=6, hidden=64)\n",
    "    train(net, loader, setup)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep-Unfolding-NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
