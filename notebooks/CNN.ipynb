{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88587486",
   "metadata": {},
   "source": [
    "Train a CNN model for beamforming using hybrid supervised and unsupervised training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fe0b93c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from typing import List, Dict\n",
    "import importlib\n",
    "# Get the current working directory\n",
    "scripts_dir = os.getcwd()\n",
    "# Go up one level\n",
    "project_root = os.path.abspath(os.path.join(scripts_dir, '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "import src.CNN\n",
    "importlib.reload(src.CNN)\n",
    "from src.CNN import ChannelCNN, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "be72f5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# Get the current working directory\n",
    "scripts_dir = os.getcwd()\n",
    "# Go up one level\n",
    "project_root = os.path.abspath(os.path.join(scripts_dir, '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "import src.utils\n",
    "importlib.reload(src.utils)\n",
    "from src.utils import calculate_sum_rate_sc\n",
    "\n",
    "import src.sc_wmmse\n",
    "importlib.reload(src.sc_wmmse)\n",
    "from src.sc_wmmse import WMMSE_alg_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "052e0b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class setup():\n",
    "    def __init__(self, n_tx, n_rx:int, num_streams:int, num_users, PT):\n",
    "        self.n_tx = n_tx\n",
    "        self.n_rx = n_rx\n",
    "        self.d = num_streams\n",
    "        self.K = num_users\n",
    "        self.PT = PT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3f631cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the setup\n",
    "num_users = 10\n",
    "n_tx = 4\n",
    "n_rx = 2\n",
    "num_streams = 2\n",
    "PT = 100\n",
    "set_up = setup(n_tx, n_rx, num_streams, num_users, PT)\n",
    "\n",
    "# Defien the CNN model and the trainer\n",
    "cn = ChannelCNN(set_up)\n",
    "tr = Trainer(set_up, cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6abf23b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/35/f3dbnk6d3ts1993_z878dt5w0000gn/T/ipykernel_32126/1939836363.py:37: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  H_dict = {str(i): row[i] for i in range(len(row))}\n",
      "/var/folders/35/f3dbnk6d3ts1993_z878dt5w0000gn/T/ipykernel_32126/1939836363.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  alph = torch.sqrt(torch.tensor(PT_sc)) / torch.sqrt(torch.tensor(sum([torch.trace(V[str(k)] @ V[str(k)].conj().T) for k in range(num_users_sc)])))\n",
      "/Users/Ali/Projects/Deep-Unfolding-NN/src/sc_wmmse.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  alph = torch.sqrt(torch.tensor(self.PT)) / torch.sqrt(torch.tensor(sum([torch.trace(V[str(k)] @ V[str(k)].conj().T) for k in range(self.K)])))\n"
     ]
    }
   ],
   "source": [
    "def proj_power(V, PT_sc):\n",
    "    num_users_sc = len(V)\n",
    "    # Projects V according to the constraint\n",
    "    alph = torch.sqrt(torch.tensor(PT_sc)) / torch.sqrt(torch.tensor(sum([torch.trace(V[str(k)] @ V[str(k)].conj().T) for k in range(num_users_sc)])))\n",
    "    V_proj = {str(k): alph * V[str(k)] for k in range(num_users_sc)}\n",
    "    return V_proj\n",
    "\n",
    "def init_V(H):\n",
    "    # Initializes V according to Hu's code\n",
    "    V = {}\n",
    "    for k in range(len(H_dict)):\n",
    "        V[str(k)] = (torch.linalg.pinv(H[str(k)] @ H[str(k)].conj().T) @ H[str(k)]).conj().T\n",
    "    return V\n",
    "\n",
    "# The setup\n",
    "num_users = 10\n",
    "n_tx = 4\n",
    "n_rx = [2] * num_users\n",
    "d = [2] * num_users\n",
    "PT = 100\n",
    "sig = [1] * num_users\n",
    "alpha = [1] * num_users\n",
    "max_iter_alg = 100\n",
    "tol_alg = 1e-3\n",
    "\n",
    "data = []\n",
    "for _ in range(100):  # 5 rows\n",
    "    row = {f'user_{i}': torch.randn(n_rx[i], n_tx, dtype=torch.cdouble) for i in range(num_users)}\n",
    "    data.append(row)\n",
    "\n",
    "H = pd.DataFrame(data)\n",
    "\n",
    "V_col = []\n",
    "V_init_col = []\n",
    "\n",
    "for idx, row in H.iterrows():\n",
    "    H_dict = {str(i): row[i] for i in range(len(row))}\n",
    "    wmm = WMMSE_alg_sc(K=num_users, n_tx=n_tx, n_rx=n_rx, H=H_dict, PT=PT, sig_k=sig, d=d, alpha=alpha, max_iter_alg=max_iter_alg, tol_alg=tol_alg)\n",
    "    V_init = init_V(H_dict)\n",
    "    V_init_proj = proj_power(V_init, PT)\n",
    "    V_l, U_l, W_l = wmm.algorithm(V_init_proj)\n",
    "    V_init_col.append(V_init_proj)\n",
    "    V_col.append(V_l[-1])\n",
    "\n",
    "V_df = pd.DataFrame(V_col)\n",
    "V_init_df = pd.DataFrame(V_init_col)\n",
    "\n",
    "# dset = pd.concat([H, V_init_df, V_df], axis=1)\n",
    "dset = pd.concat([H, V_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f88a8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_0</th>\n",
       "      <th>user_1</th>\n",
       "      <th>user_2</th>\n",
       "      <th>user_3</th>\n",
       "      <th>user_4</th>\n",
       "      <th>user_5</th>\n",
       "      <th>user_6</th>\n",
       "      <th>user_7</th>\n",
       "      <th>user_8</th>\n",
       "      <th>user_9</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[tensor(-0.3174+0.2691j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(-0.7710-0.6892j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(0.4248-0.7853j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-0.6270-0.4134j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(0.8697+0.2104j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-1.3601-0.5822j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(-1.4476-0.1881j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(0.6659-0.6918j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(0.6049+0.2167j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(0.1799-1.4796j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(1.3000-1.8167j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-4.2119e-116-3.0417e-116j, dtype=torc...</td>\n",
       "      <td>[[tensor(0.2109-1.6266j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-0.9600+0.5363j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(-1.2858e-114-8.3430e-115j, dtype=torc...</td>\n",
       "      <td>[[tensor(3.5927e-119+5.1662e-119j, dtype=torch...</td>\n",
       "      <td>[[tensor(1.4389e-116-1.2445e-115j, dtype=torch...</td>\n",
       "      <td>[[tensor(-5.7934e-120+3.3107e-121j, dtype=torc...</td>\n",
       "      <td>[[tensor(-1.5601+0.9222j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(5.6921e-115+9.3346e-116j, dtype=torch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[tensor(0.6888-0.2492j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-1.1235+0.3720j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(-1.6394-0.5866j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(-0.9216-1.2958j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(-0.6637+0.1286j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(0.5788-1.3278j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-0.6855+0.8910j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(-0.3278+0.3371j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(0.4953-1.2797j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(0.3691+0.3681j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(1.5345-0.7531j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(8.7742e-135-6.2374e-135j, dtype=torch...</td>\n",
       "      <td>[[tensor(-1.8854e-133+9.1612e-133j, dtype=torc...</td>\n",
       "      <td>[[tensor(-0.0496-0.0210j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(-1.0812-1.3502j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(-7.6978e-137+1.0926e-136j, dtype=torc...</td>\n",
       "      <td>[[tensor(2.1594e-136-1.2636e-136j, dtype=torch...</td>\n",
       "      <td>[[tensor(5.8188e-133+5.4773e-133j, dtype=torch...</td>\n",
       "      <td>[[tensor(2.4930e-129+2.9628e-129j, dtype=torch...</td>\n",
       "      <td>[[tensor(3.4713-1.2082j, dtype=torch.complex12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[tensor(1.3437-0.7390j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-0.4524-0.0027j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(-0.0045+0.9367j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(0.0475-1.3670j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(1.3733-0.4788j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-0.5951-0.4008j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(0.0137+1.3554j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(0.5322-0.2477j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-1.2356+0.6202j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(0.5391-1.4007j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-1.8504e-131-5.2960e-133j, dtype=torc...</td>\n",
       "      <td>[[tensor(-3.0267e-126+2.2739e-126j, dtype=torc...</td>\n",
       "      <td>[[tensor(2.5817-0.8452j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-0.5726+0.0891j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(1.6840e-138+4.7683e-138j, dtype=torch...</td>\n",
       "      <td>[[tensor(3.2245e-128+1.3623e-128j, dtype=torch...</td>\n",
       "      <td>[[tensor(-2.0110e-138-2.7966e-137j, dtype=torc...</td>\n",
       "      <td>[[tensor(-1.7747e-125+1.2775e-125j, dtype=torc...</td>\n",
       "      <td>[[tensor(-0.1810+0.3051j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(0.3164-0.7610j, dtype=torch.complex12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[tensor(-0.6601+1.2663j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(0.4808-0.1574j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(0.1407+0.1795j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(0.1139+1.3220j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(1.0005+0.9430j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-0.0556-1.3588j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(0.9017-0.5273j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(0.0731-0.5748j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-0.3227-1.1620j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(0.2688+0.5712j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(1.5771e-143+3.2965e-144j, dtype=torch...</td>\n",
       "      <td>[[tensor(2.7675+1.9298j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(0.3285-1.0953j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-3.4300e-146+5.6060e-146j, dtype=torc...</td>\n",
       "      <td>[[tensor(-5.6638e-149+5.1512e-149j, dtype=torc...</td>\n",
       "      <td>[[tensor(-0.2813+2.3720j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(2.2152e-150+8.4328e-151j, dtype=torch...</td>\n",
       "      <td>[[tensor(-1.1325e-149-3.1718e-149j, dtype=torc...</td>\n",
       "      <td>[[tensor(-4.3557e-145+8.6984e-145j, dtype=torc...</td>\n",
       "      <td>[[tensor(0.0219+0.9383j, dtype=torch.complex12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[tensor(-1.1457-0.3892j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(-0.5187-0.3638j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(0.7049-1.3787j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(0.2324+0.3872j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(0.1782-1.3190j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-0.5742-0.5926j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(0.2066+0.6997j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(1.2183+0.3556j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(0.3444+0.2601j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-0.2001-0.9365j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(-3.1969e-119+3.4601e-119j, dtype=torc...</td>\n",
       "      <td>[[tensor(8.2181e-120+5.6860e-120j, dtype=torch...</td>\n",
       "      <td>[[tensor(3.5252e-117-4.1327e-118j, dtype=torch...</td>\n",
       "      <td>[[tensor(-3.0041+0.6439j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(1.2168+0.3968j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(7.2271e-127+1.0092e-125j, dtype=torch...</td>\n",
       "      <td>[[tensor(0.8348-0.2216j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(3.6027e-113+1.5094e-113j, dtype=torch...</td>\n",
       "      <td>[[tensor(0.1647+1.1165j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-1.3514e-114+3.8123e-113j, dtype=torc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[[tensor(-0.6088-0.0546j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(0.8194+0.4362j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(0.7557-0.3543j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-0.7104+0.7286j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(-0.5020-0.0752j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(-0.3098-1.1018j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(-0.0142+1.4732j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(0.3815+0.2055j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(0.0537+1.0362j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-0.3763+0.5018j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(1.2816e-131-1.0220e-131j, dtype=torch...</td>\n",
       "      <td>[[tensor(4.9990e-136-7.6478e-136j, dtype=torch...</td>\n",
       "      <td>[[tensor(-0.1010+2.5646j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(1.2801-1.7102j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-1.6707e-141+2.2302e-141j, dtype=torc...</td>\n",
       "      <td>[[tensor(-0.1803+1.7907j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(-1.9609e-135-5.5042e-135j, dtype=torc...</td>\n",
       "      <td>[[tensor(3.0529e-135-9.8636e-135j, dtype=torch...</td>\n",
       "      <td>[[tensor(0.8597-1.0150j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(4.1144e-135-2.6097e-135j, dtype=torch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[[tensor(-0.1900+1.2547j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(0.7454-0.6015j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(1.1742+0.6464j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-0.5767-0.5780j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(-0.1007+0.3206j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(-0.6714-1.4303j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(-1.0949+1.1514j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(-1.8528-0.7419j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(0.3167-0.3425j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(0.6074+0.6445j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-1.0298e-141+3.6699e-142j, dtype=torc...</td>\n",
       "      <td>[[tensor(-0.9617-0.9644j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(1.8353e-153-1.1318e-153j, dtype=torch...</td>\n",
       "      <td>[[tensor(4.7301e-135+1.1359e-135j, dtype=torch...</td>\n",
       "      <td>[[tensor(1.3989e-132+5.1728e-133j, dtype=torch...</td>\n",
       "      <td>[[tensor(-0.1421+0.5318j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(-1.8375-1.8440j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(-6.2447e-134-1.2458e-133j, dtype=torc...</td>\n",
       "      <td>[[tensor(4.7317e-144+8.3788e-145j, dtype=torch...</td>\n",
       "      <td>[[tensor(0.1092-1.5870j, dtype=torch.complex12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>[[tensor(0.2988-0.5356j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(0.2767-0.3987j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-1.1543-0.3206j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(-0.1231-0.3255j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(0.2651-0.4744j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-0.5378+1.0899j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(1.3002+0.2406j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(0.1588+0.8089j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(0.7797-0.3146j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(0.2387-0.0212j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-8.2888e-139+2.4874e-137j, dtype=torc...</td>\n",
       "      <td>[[tensor(-7.3419e-141+3.9877e-141j, dtype=torc...</td>\n",
       "      <td>[[tensor(4.2468e-138+3.1632e-136j, dtype=torch...</td>\n",
       "      <td>[[tensor(-1.0083-0.2633j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(1.6228+2.3862j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-8.3534e-136-9.1173e-135j, dtype=torc...</td>\n",
       "      <td>[[tensor(0.3454-0.1749j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(9.4920e-136+3.3639e-135j, dtype=torch...</td>\n",
       "      <td>[[tensor(1.5973+0.5338j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-5.6862e-137+9.2612e-137j, dtype=torc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>[[tensor(0.4059+0.6422j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(0.8847+0.8704j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-1.0500+0.1156j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(-0.1382-0.4882j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(-0.4448-0.7660j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(-0.1140-0.1818j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(0.4456+0.1822j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-1.1319+0.4771j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(-0.3598+0.4189j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(-1.3604+0.9766j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(-4.4157e-140+4.0215e-140j, dtype=torc...</td>\n",
       "      <td>[[tensor(0.0489-0.0732j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-1.6792+0.1214j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(-1.2866e-140-2.8609e-140j, dtype=torc...</td>\n",
       "      <td>[[tensor(4.1239e-138+4.0187e-138j, dtype=torch...</td>\n",
       "      <td>[[tensor(-2.9156e-139-1.0618e-137j, dtype=torc...</td>\n",
       "      <td>[[tensor(-0.1478-0.0582j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(-1.1418e-137+2.3040e-138j, dtype=torc...</td>\n",
       "      <td>[[tensor(9.7275e-139+3.1383e-139j, dtype=torch...</td>\n",
       "      <td>[[tensor(0.4272-1.0651j, dtype=torch.complex12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>[[tensor(1.0426-0.3598j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-0.7822+0.1623j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(-0.4381-1.5082j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(0.2779-0.6630j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-0.6237+0.7262j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(0.9432+1.1248j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(0.6203-1.2054j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-0.0264-0.1892j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(0.3900+0.9824j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(0.3762+0.6819j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-1.8275e-141+2.4541e-142j, dtype=torc...</td>\n",
       "      <td>[[tensor(6.2033e-135-3.4078e-135j, dtype=torch...</td>\n",
       "      <td>[[tensor(0.1097+0.6470j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(9.0552e-139-2.2214e-138j, dtype=torch...</td>\n",
       "      <td>[[tensor(0.2201-0.9383j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-2.4193e-131+5.3175e-131j, dtype=torc...</td>\n",
       "      <td>[[tensor(0.0779+1.9895j, dtype=torch.complex12...</td>\n",
       "      <td>[[tensor(-0.2124-1.1009j, dtype=torch.complex1...</td>\n",
       "      <td>[[tensor(-1.6693e-141-3.2158e-142j, dtype=torc...</td>\n",
       "      <td>[[tensor(-1.5592e-137+9.8381e-138j, dtype=torc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               user_0  \\\n",
       "0   [[tensor(-0.3174+0.2691j, dtype=torch.complex1...   \n",
       "1   [[tensor(0.6888-0.2492j, dtype=torch.complex12...   \n",
       "2   [[tensor(1.3437-0.7390j, dtype=torch.complex12...   \n",
       "3   [[tensor(-0.6601+1.2663j, dtype=torch.complex1...   \n",
       "4   [[tensor(-1.1457-0.3892j, dtype=torch.complex1...   \n",
       "..                                                ...   \n",
       "95  [[tensor(-0.6088-0.0546j, dtype=torch.complex1...   \n",
       "96  [[tensor(-0.1900+1.2547j, dtype=torch.complex1...   \n",
       "97  [[tensor(0.2988-0.5356j, dtype=torch.complex12...   \n",
       "98  [[tensor(0.4059+0.6422j, dtype=torch.complex12...   \n",
       "99  [[tensor(1.0426-0.3598j, dtype=torch.complex12...   \n",
       "\n",
       "                                               user_1  \\\n",
       "0   [[tensor(-0.7710-0.6892j, dtype=torch.complex1...   \n",
       "1   [[tensor(-1.1235+0.3720j, dtype=torch.complex1...   \n",
       "2   [[tensor(-0.4524-0.0027j, dtype=torch.complex1...   \n",
       "3   [[tensor(0.4808-0.1574j, dtype=torch.complex12...   \n",
       "4   [[tensor(-0.5187-0.3638j, dtype=torch.complex1...   \n",
       "..                                                ...   \n",
       "95  [[tensor(0.8194+0.4362j, dtype=torch.complex12...   \n",
       "96  [[tensor(0.7454-0.6015j, dtype=torch.complex12...   \n",
       "97  [[tensor(0.2767-0.3987j, dtype=torch.complex12...   \n",
       "98  [[tensor(0.8847+0.8704j, dtype=torch.complex12...   \n",
       "99  [[tensor(-0.7822+0.1623j, dtype=torch.complex1...   \n",
       "\n",
       "                                               user_2  \\\n",
       "0   [[tensor(0.4248-0.7853j, dtype=torch.complex12...   \n",
       "1   [[tensor(-1.6394-0.5866j, dtype=torch.complex1...   \n",
       "2   [[tensor(-0.0045+0.9367j, dtype=torch.complex1...   \n",
       "3   [[tensor(0.1407+0.1795j, dtype=torch.complex12...   \n",
       "4   [[tensor(0.7049-1.3787j, dtype=torch.complex12...   \n",
       "..                                                ...   \n",
       "95  [[tensor(0.7557-0.3543j, dtype=torch.complex12...   \n",
       "96  [[tensor(1.1742+0.6464j, dtype=torch.complex12...   \n",
       "97  [[tensor(-1.1543-0.3206j, dtype=torch.complex1...   \n",
       "98  [[tensor(-1.0500+0.1156j, dtype=torch.complex1...   \n",
       "99  [[tensor(-0.4381-1.5082j, dtype=torch.complex1...   \n",
       "\n",
       "                                               user_3  \\\n",
       "0   [[tensor(-0.6270-0.4134j, dtype=torch.complex1...   \n",
       "1   [[tensor(-0.9216-1.2958j, dtype=torch.complex1...   \n",
       "2   [[tensor(0.0475-1.3670j, dtype=torch.complex12...   \n",
       "3   [[tensor(0.1139+1.3220j, dtype=torch.complex12...   \n",
       "4   [[tensor(0.2324+0.3872j, dtype=torch.complex12...   \n",
       "..                                                ...   \n",
       "95  [[tensor(-0.7104+0.7286j, dtype=torch.complex1...   \n",
       "96  [[tensor(-0.5767-0.5780j, dtype=torch.complex1...   \n",
       "97  [[tensor(-0.1231-0.3255j, dtype=torch.complex1...   \n",
       "98  [[tensor(-0.1382-0.4882j, dtype=torch.complex1...   \n",
       "99  [[tensor(0.2779-0.6630j, dtype=torch.complex12...   \n",
       "\n",
       "                                               user_4  \\\n",
       "0   [[tensor(0.8697+0.2104j, dtype=torch.complex12...   \n",
       "1   [[tensor(-0.6637+0.1286j, dtype=torch.complex1...   \n",
       "2   [[tensor(1.3733-0.4788j, dtype=torch.complex12...   \n",
       "3   [[tensor(1.0005+0.9430j, dtype=torch.complex12...   \n",
       "4   [[tensor(0.1782-1.3190j, dtype=torch.complex12...   \n",
       "..                                                ...   \n",
       "95  [[tensor(-0.5020-0.0752j, dtype=torch.complex1...   \n",
       "96  [[tensor(-0.1007+0.3206j, dtype=torch.complex1...   \n",
       "97  [[tensor(0.2651-0.4744j, dtype=torch.complex12...   \n",
       "98  [[tensor(-0.4448-0.7660j, dtype=torch.complex1...   \n",
       "99  [[tensor(-0.6237+0.7262j, dtype=torch.complex1...   \n",
       "\n",
       "                                               user_5  \\\n",
       "0   [[tensor(-1.3601-0.5822j, dtype=torch.complex1...   \n",
       "1   [[tensor(0.5788-1.3278j, dtype=torch.complex12...   \n",
       "2   [[tensor(-0.5951-0.4008j, dtype=torch.complex1...   \n",
       "3   [[tensor(-0.0556-1.3588j, dtype=torch.complex1...   \n",
       "4   [[tensor(-0.5742-0.5926j, dtype=torch.complex1...   \n",
       "..                                                ...   \n",
       "95  [[tensor(-0.3098-1.1018j, dtype=torch.complex1...   \n",
       "96  [[tensor(-0.6714-1.4303j, dtype=torch.complex1...   \n",
       "97  [[tensor(-0.5378+1.0899j, dtype=torch.complex1...   \n",
       "98  [[tensor(-0.1140-0.1818j, dtype=torch.complex1...   \n",
       "99  [[tensor(0.9432+1.1248j, dtype=torch.complex12...   \n",
       "\n",
       "                                               user_6  \\\n",
       "0   [[tensor(-1.4476-0.1881j, dtype=torch.complex1...   \n",
       "1   [[tensor(-0.6855+0.8910j, dtype=torch.complex1...   \n",
       "2   [[tensor(0.0137+1.3554j, dtype=torch.complex12...   \n",
       "3   [[tensor(0.9017-0.5273j, dtype=torch.complex12...   \n",
       "4   [[tensor(0.2066+0.6997j, dtype=torch.complex12...   \n",
       "..                                                ...   \n",
       "95  [[tensor(-0.0142+1.4732j, dtype=torch.complex1...   \n",
       "96  [[tensor(-1.0949+1.1514j, dtype=torch.complex1...   \n",
       "97  [[tensor(1.3002+0.2406j, dtype=torch.complex12...   \n",
       "98  [[tensor(0.4456+0.1822j, dtype=torch.complex12...   \n",
       "99  [[tensor(0.6203-1.2054j, dtype=torch.complex12...   \n",
       "\n",
       "                                               user_7  \\\n",
       "0   [[tensor(0.6659-0.6918j, dtype=torch.complex12...   \n",
       "1   [[tensor(-0.3278+0.3371j, dtype=torch.complex1...   \n",
       "2   [[tensor(0.5322-0.2477j, dtype=torch.complex12...   \n",
       "3   [[tensor(0.0731-0.5748j, dtype=torch.complex12...   \n",
       "4   [[tensor(1.2183+0.3556j, dtype=torch.complex12...   \n",
       "..                                                ...   \n",
       "95  [[tensor(0.3815+0.2055j, dtype=torch.complex12...   \n",
       "96  [[tensor(-1.8528-0.7419j, dtype=torch.complex1...   \n",
       "97  [[tensor(0.1588+0.8089j, dtype=torch.complex12...   \n",
       "98  [[tensor(-1.1319+0.4771j, dtype=torch.complex1...   \n",
       "99  [[tensor(-0.0264-0.1892j, dtype=torch.complex1...   \n",
       "\n",
       "                                               user_8  \\\n",
       "0   [[tensor(0.6049+0.2167j, dtype=torch.complex12...   \n",
       "1   [[tensor(0.4953-1.2797j, dtype=torch.complex12...   \n",
       "2   [[tensor(-1.2356+0.6202j, dtype=torch.complex1...   \n",
       "3   [[tensor(-0.3227-1.1620j, dtype=torch.complex1...   \n",
       "4   [[tensor(0.3444+0.2601j, dtype=torch.complex12...   \n",
       "..                                                ...   \n",
       "95  [[tensor(0.0537+1.0362j, dtype=torch.complex12...   \n",
       "96  [[tensor(0.3167-0.3425j, dtype=torch.complex12...   \n",
       "97  [[tensor(0.7797-0.3146j, dtype=torch.complex12...   \n",
       "98  [[tensor(-0.3598+0.4189j, dtype=torch.complex1...   \n",
       "99  [[tensor(0.3900+0.9824j, dtype=torch.complex12...   \n",
       "\n",
       "                                               user_9  \\\n",
       "0   [[tensor(0.1799-1.4796j, dtype=torch.complex12...   \n",
       "1   [[tensor(0.3691+0.3681j, dtype=torch.complex12...   \n",
       "2   [[tensor(0.5391-1.4007j, dtype=torch.complex12...   \n",
       "3   [[tensor(0.2688+0.5712j, dtype=torch.complex12...   \n",
       "4   [[tensor(-0.2001-0.9365j, dtype=torch.complex1...   \n",
       "..                                                ...   \n",
       "95  [[tensor(-0.3763+0.5018j, dtype=torch.complex1...   \n",
       "96  [[tensor(0.6074+0.6445j, dtype=torch.complex12...   \n",
       "97  [[tensor(0.2387-0.0212j, dtype=torch.complex12...   \n",
       "98  [[tensor(-1.3604+0.9766j, dtype=torch.complex1...   \n",
       "99  [[tensor(0.3762+0.6819j, dtype=torch.complex12...   \n",
       "\n",
       "                                                    0  \\\n",
       "0   [[tensor(1.3000-1.8167j, dtype=torch.complex12...   \n",
       "1   [[tensor(1.5345-0.7531j, dtype=torch.complex12...   \n",
       "2   [[tensor(-1.8504e-131-5.2960e-133j, dtype=torc...   \n",
       "3   [[tensor(1.5771e-143+3.2965e-144j, dtype=torch...   \n",
       "4   [[tensor(-3.1969e-119+3.4601e-119j, dtype=torc...   \n",
       "..                                                ...   \n",
       "95  [[tensor(1.2816e-131-1.0220e-131j, dtype=torch...   \n",
       "96  [[tensor(-1.0298e-141+3.6699e-142j, dtype=torc...   \n",
       "97  [[tensor(-8.2888e-139+2.4874e-137j, dtype=torc...   \n",
       "98  [[tensor(-4.4157e-140+4.0215e-140j, dtype=torc...   \n",
       "99  [[tensor(-1.8275e-141+2.4541e-142j, dtype=torc...   \n",
       "\n",
       "                                                    1  \\\n",
       "0   [[tensor(-4.2119e-116-3.0417e-116j, dtype=torc...   \n",
       "1   [[tensor(8.7742e-135-6.2374e-135j, dtype=torch...   \n",
       "2   [[tensor(-3.0267e-126+2.2739e-126j, dtype=torc...   \n",
       "3   [[tensor(2.7675+1.9298j, dtype=torch.complex12...   \n",
       "4   [[tensor(8.2181e-120+5.6860e-120j, dtype=torch...   \n",
       "..                                                ...   \n",
       "95  [[tensor(4.9990e-136-7.6478e-136j, dtype=torch...   \n",
       "96  [[tensor(-0.9617-0.9644j, dtype=torch.complex1...   \n",
       "97  [[tensor(-7.3419e-141+3.9877e-141j, dtype=torc...   \n",
       "98  [[tensor(0.0489-0.0732j, dtype=torch.complex12...   \n",
       "99  [[tensor(6.2033e-135-3.4078e-135j, dtype=torch...   \n",
       "\n",
       "                                                    2  \\\n",
       "0   [[tensor(0.2109-1.6266j, dtype=torch.complex12...   \n",
       "1   [[tensor(-1.8854e-133+9.1612e-133j, dtype=torc...   \n",
       "2   [[tensor(2.5817-0.8452j, dtype=torch.complex12...   \n",
       "3   [[tensor(0.3285-1.0953j, dtype=torch.complex12...   \n",
       "4   [[tensor(3.5252e-117-4.1327e-118j, dtype=torch...   \n",
       "..                                                ...   \n",
       "95  [[tensor(-0.1010+2.5646j, dtype=torch.complex1...   \n",
       "96  [[tensor(1.8353e-153-1.1318e-153j, dtype=torch...   \n",
       "97  [[tensor(4.2468e-138+3.1632e-136j, dtype=torch...   \n",
       "98  [[tensor(-1.6792+0.1214j, dtype=torch.complex1...   \n",
       "99  [[tensor(0.1097+0.6470j, dtype=torch.complex12...   \n",
       "\n",
       "                                                    3  \\\n",
       "0   [[tensor(-0.9600+0.5363j, dtype=torch.complex1...   \n",
       "1   [[tensor(-0.0496-0.0210j, dtype=torch.complex1...   \n",
       "2   [[tensor(-0.5726+0.0891j, dtype=torch.complex1...   \n",
       "3   [[tensor(-3.4300e-146+5.6060e-146j, dtype=torc...   \n",
       "4   [[tensor(-3.0041+0.6439j, dtype=torch.complex1...   \n",
       "..                                                ...   \n",
       "95  [[tensor(1.2801-1.7102j, dtype=torch.complex12...   \n",
       "96  [[tensor(4.7301e-135+1.1359e-135j, dtype=torch...   \n",
       "97  [[tensor(-1.0083-0.2633j, dtype=torch.complex1...   \n",
       "98  [[tensor(-1.2866e-140-2.8609e-140j, dtype=torc...   \n",
       "99  [[tensor(9.0552e-139-2.2214e-138j, dtype=torch...   \n",
       "\n",
       "                                                    4  \\\n",
       "0   [[tensor(-1.2858e-114-8.3430e-115j, dtype=torc...   \n",
       "1   [[tensor(-1.0812-1.3502j, dtype=torch.complex1...   \n",
       "2   [[tensor(1.6840e-138+4.7683e-138j, dtype=torch...   \n",
       "3   [[tensor(-5.6638e-149+5.1512e-149j, dtype=torc...   \n",
       "4   [[tensor(1.2168+0.3968j, dtype=torch.complex12...   \n",
       "..                                                ...   \n",
       "95  [[tensor(-1.6707e-141+2.2302e-141j, dtype=torc...   \n",
       "96  [[tensor(1.3989e-132+5.1728e-133j, dtype=torch...   \n",
       "97  [[tensor(1.6228+2.3862j, dtype=torch.complex12...   \n",
       "98  [[tensor(4.1239e-138+4.0187e-138j, dtype=torch...   \n",
       "99  [[tensor(0.2201-0.9383j, dtype=torch.complex12...   \n",
       "\n",
       "                                                    5  \\\n",
       "0   [[tensor(3.5927e-119+5.1662e-119j, dtype=torch...   \n",
       "1   [[tensor(-7.6978e-137+1.0926e-136j, dtype=torc...   \n",
       "2   [[tensor(3.2245e-128+1.3623e-128j, dtype=torch...   \n",
       "3   [[tensor(-0.2813+2.3720j, dtype=torch.complex1...   \n",
       "4   [[tensor(7.2271e-127+1.0092e-125j, dtype=torch...   \n",
       "..                                                ...   \n",
       "95  [[tensor(-0.1803+1.7907j, dtype=torch.complex1...   \n",
       "96  [[tensor(-0.1421+0.5318j, dtype=torch.complex1...   \n",
       "97  [[tensor(-8.3534e-136-9.1173e-135j, dtype=torc...   \n",
       "98  [[tensor(-2.9156e-139-1.0618e-137j, dtype=torc...   \n",
       "99  [[tensor(-2.4193e-131+5.3175e-131j, dtype=torc...   \n",
       "\n",
       "                                                    6  \\\n",
       "0   [[tensor(1.4389e-116-1.2445e-115j, dtype=torch...   \n",
       "1   [[tensor(2.1594e-136-1.2636e-136j, dtype=torch...   \n",
       "2   [[tensor(-2.0110e-138-2.7966e-137j, dtype=torc...   \n",
       "3   [[tensor(2.2152e-150+8.4328e-151j, dtype=torch...   \n",
       "4   [[tensor(0.8348-0.2216j, dtype=torch.complex12...   \n",
       "..                                                ...   \n",
       "95  [[tensor(-1.9609e-135-5.5042e-135j, dtype=torc...   \n",
       "96  [[tensor(-1.8375-1.8440j, dtype=torch.complex1...   \n",
       "97  [[tensor(0.3454-0.1749j, dtype=torch.complex12...   \n",
       "98  [[tensor(-0.1478-0.0582j, dtype=torch.complex1...   \n",
       "99  [[tensor(0.0779+1.9895j, dtype=torch.complex12...   \n",
       "\n",
       "                                                    7  \\\n",
       "0   [[tensor(-5.7934e-120+3.3107e-121j, dtype=torc...   \n",
       "1   [[tensor(5.8188e-133+5.4773e-133j, dtype=torch...   \n",
       "2   [[tensor(-1.7747e-125+1.2775e-125j, dtype=torc...   \n",
       "3   [[tensor(-1.1325e-149-3.1718e-149j, dtype=torc...   \n",
       "4   [[tensor(3.6027e-113+1.5094e-113j, dtype=torch...   \n",
       "..                                                ...   \n",
       "95  [[tensor(3.0529e-135-9.8636e-135j, dtype=torch...   \n",
       "96  [[tensor(-6.2447e-134-1.2458e-133j, dtype=torc...   \n",
       "97  [[tensor(9.4920e-136+3.3639e-135j, dtype=torch...   \n",
       "98  [[tensor(-1.1418e-137+2.3040e-138j, dtype=torc...   \n",
       "99  [[tensor(-0.2124-1.1009j, dtype=torch.complex1...   \n",
       "\n",
       "                                                    8  \\\n",
       "0   [[tensor(-1.5601+0.9222j, dtype=torch.complex1...   \n",
       "1   [[tensor(2.4930e-129+2.9628e-129j, dtype=torch...   \n",
       "2   [[tensor(-0.1810+0.3051j, dtype=torch.complex1...   \n",
       "3   [[tensor(-4.3557e-145+8.6984e-145j, dtype=torc...   \n",
       "4   [[tensor(0.1647+1.1165j, dtype=torch.complex12...   \n",
       "..                                                ...   \n",
       "95  [[tensor(0.8597-1.0150j, dtype=torch.complex12...   \n",
       "96  [[tensor(4.7317e-144+8.3788e-145j, dtype=torch...   \n",
       "97  [[tensor(1.5973+0.5338j, dtype=torch.complex12...   \n",
       "98  [[tensor(9.7275e-139+3.1383e-139j, dtype=torch...   \n",
       "99  [[tensor(-1.6693e-141-3.2158e-142j, dtype=torc...   \n",
       "\n",
       "                                                    9  \n",
       "0   [[tensor(5.6921e-115+9.3346e-116j, dtype=torch...  \n",
       "1   [[tensor(3.4713-1.2082j, dtype=torch.complex12...  \n",
       "2   [[tensor(0.3164-0.7610j, dtype=torch.complex12...  \n",
       "3   [[tensor(0.0219+0.9383j, dtype=torch.complex12...  \n",
       "4   [[tensor(-1.3514e-114+3.8123e-113j, dtype=torc...  \n",
       "..                                                ...  \n",
       "95  [[tensor(4.1144e-135-2.6097e-135j, dtype=torch...  \n",
       "96  [[tensor(0.1092-1.5870j, dtype=torch.complex12...  \n",
       "97  [[tensor(-5.6862e-137+9.2612e-137j, dtype=torc...  \n",
       "98  [[tensor(0.4272-1.0651j, dtype=torch.complex12...  \n",
       "99  [[tensor(-1.5592e-137+9.8381e-138j, dtype=torc...  \n",
       "\n",
       "[100 rows x 20 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9281516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset dataframe\n",
    "def complex_tensor():\n",
    "    real = torch.randn(2, 8)\n",
    "    imag = torch.randn(2, 8)\n",
    "    return real + 1j * imag\n",
    "\n",
    "# Create the DataFrame\n",
    "H_df = pd.DataFrame([[complex_tensor() for _ in range(4)] for _ in range(10)])\n",
    "\n",
    "def complex_tensor():\n",
    "    real = torch.randn(8, 2)\n",
    "    imag = torch.randn(8, 2)\n",
    "    return real + 1j * imag\n",
    "\n",
    "# Create the DataFrame\n",
    "V_df = pd.DataFrame([[complex_tensor() for _ in range(4)] for _ in range(10)])\n",
    "\n",
    "dataset = pd.concat([H_df, V_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9493a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[tensor(-0.0671-0.7584j), tensor(0.7654-1.669...</td>\n",
       "      <td>[[tensor(-0.0850+2.0890j), tensor(0.6860-1.006...</td>\n",
       "      <td>[[tensor(-1.4190-0.3194j), tensor(-1.3981-0.36...</td>\n",
       "      <td>[[tensor(-2.0406+1.2129j), tensor(-0.7994+0.01...</td>\n",
       "      <td>[[tensor(-2.2761-1.4484j), tensor(1.2999+2.947...</td>\n",
       "      <td>[[tensor(-1.2215+0.9061j), tensor(-0.2374-0.64...</td>\n",
       "      <td>[[tensor(0.3742+0.6502j), tensor(0.4598-0.5954...</td>\n",
       "      <td>[[tensor(1.7330-1.3346j), tensor(0.8281+1.9333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[tensor(-2.3240+1.3299j), tensor(-1.3996+0.09...</td>\n",
       "      <td>[[tensor(0.9684-1.7266j), tensor(-0.6797-1.840...</td>\n",
       "      <td>[[tensor(1.7691-0.2782j), tensor(-0.9194-0.153...</td>\n",
       "      <td>[[tensor(-1.2872+0.0022j), tensor(-1.2818+1.72...</td>\n",
       "      <td>[[tensor(-0.1527+0.1605j), tensor(0.6668+1.747...</td>\n",
       "      <td>[[tensor(0.8145+2.4532j), tensor(0.5506-0.3737...</td>\n",
       "      <td>[[tensor(0.8166-0.2685j), tensor(3.1040-0.6226...</td>\n",
       "      <td>[[tensor(-0.4254+2.0138j), tensor(0.5117+1.658...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[tensor(0.8616-1.6796j), tensor(0.0656-0.5628...</td>\n",
       "      <td>[[tensor(-0.4451+0.3902j), tensor(-1.4060-0.46...</td>\n",
       "      <td>[[tensor(-0.3006-2.9138j), tensor(0.8641+0.980...</td>\n",
       "      <td>[[tensor(-0.9107+2.1415j), tensor(1.9554+0.650...</td>\n",
       "      <td>[[tensor(0.5721+1.4493j), tensor(-0.4224+0.954...</td>\n",
       "      <td>[[tensor(-2.3652+1.0367j), tensor(-0.8970-0.12...</td>\n",
       "      <td>[[tensor(0.9812+1.7056j), tensor(0.7562+0.0377...</td>\n",
       "      <td>[[tensor(-0.7285-1.4143j), tensor(0.0571-0.711...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[tensor(0.5128+2.2246j), tensor(-0.7010-1.415...</td>\n",
       "      <td>[[tensor(-1.1856-0.4819j), tensor(0.6214-1.416...</td>\n",
       "      <td>[[tensor(-0.1885-1.3662j), tensor(-0.7833+0.60...</td>\n",
       "      <td>[[tensor(-0.6910+0.2716j), tensor(-0.6368-0.91...</td>\n",
       "      <td>[[tensor(0.5218-0.5860j), tensor(0.1351-0.2889...</td>\n",
       "      <td>[[tensor(1.2143+0.7065j), tensor(-0.1696+0.120...</td>\n",
       "      <td>[[tensor(-0.1198-1.0393j), tensor(-0.8785+2.16...</td>\n",
       "      <td>[[tensor(-0.8914+1.4690j), tensor(0.8811+0.652...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[tensor(-1.1951-0.9662j), tensor(1.7508+1.108...</td>\n",
       "      <td>[[tensor(0.1701+0.3513j), tensor(-0.5437-0.729...</td>\n",
       "      <td>[[tensor(0.7469-0.8845j), tensor(0.9412+0.3307...</td>\n",
       "      <td>[[tensor(-0.0068+0.3495j), tensor(0.3833+0.256...</td>\n",
       "      <td>[[tensor(0.1751-0.2768j), tensor(0.2558-1.0891...</td>\n",
       "      <td>[[tensor(-0.7947-1.2705j), tensor(-0.2561-0.26...</td>\n",
       "      <td>[[tensor(-0.6154-0.4045j), tensor(0.8162+0.045...</td>\n",
       "      <td>[[tensor(-0.6924-0.2615j), tensor(1.9418+0.535...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[tensor(-1.2995-2.5753j), tensor(0.2858-2.326...</td>\n",
       "      <td>[[tensor(0.6334-0.2164j), tensor(-2.9397-0.008...</td>\n",
       "      <td>[[tensor(0.4459+1.3150j), tensor(0.4346+1.4968...</td>\n",
       "      <td>[[tensor(-0.3480+0.3138j), tensor(-0.5462+0.45...</td>\n",
       "      <td>[[tensor(-0.1475-1.3746j), tensor(0.2122+0.293...</td>\n",
       "      <td>[[tensor(1.0587-0.1317j), tensor(0.9242+0.4298...</td>\n",
       "      <td>[[tensor(-0.1584+1.2031j), tensor(0.7313+0.937...</td>\n",
       "      <td>[[tensor(0.1070-0.8492j), tensor(1.1959+0.3698...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[tensor(-0.2393-0.1396j), tensor(-0.0497+2.16...</td>\n",
       "      <td>[[tensor(-0.3758+1.2095j), tensor(0.3108+0.605...</td>\n",
       "      <td>[[tensor(-0.5330-0.2716j), tensor(-0.1520+0.48...</td>\n",
       "      <td>[[tensor(-0.9080+0.7858j), tensor(0.3499-0.972...</td>\n",
       "      <td>[[tensor(0.5895+2.2349j), tensor(0.2653-3.3129...</td>\n",
       "      <td>[[tensor(1.5641-1.3597j), tensor(0.5240+0.8918...</td>\n",
       "      <td>[[tensor(-2.5834-0.5254j), tensor(1.2642+0.369...</td>\n",
       "      <td>[[tensor(-0.2199-0.6399j), tensor(-0.8450+1.34...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[tensor(0.2745+0.4996j), tensor(0.4409-0.3289...</td>\n",
       "      <td>[[tensor(1.4717-1.4084j), tensor(0.8559+0.8322...</td>\n",
       "      <td>[[tensor(-0.7999-1.4514j), tensor(1.3643-0.084...</td>\n",
       "      <td>[[tensor(0.6672-0.8128j), tensor(-1.0016+0.993...</td>\n",
       "      <td>[[tensor(1.8183+0.4838j), tensor(-0.3537-0.831...</td>\n",
       "      <td>[[tensor(0.8323+1.6676j), tensor(0.4486+1.1067...</td>\n",
       "      <td>[[tensor(-0.4147-0.1938j), tensor(-0.0886-0.66...</td>\n",
       "      <td>[[tensor(-1.6282-0.8072j), tensor(-0.2779+1.31...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[tensor(1.1549+1.7577j), tensor(-0.0731+0.357...</td>\n",
       "      <td>[[tensor(0.4737-0.2838j), tensor(-0.3717-0.338...</td>\n",
       "      <td>[[tensor(-0.4688+0.0398j), tensor(0.7929+0.196...</td>\n",
       "      <td>[[tensor(1.8209-0.4706j), tensor(-0.0160+0.742...</td>\n",
       "      <td>[[tensor(2.3053+0.5111j), tensor(-0.5735+2.072...</td>\n",
       "      <td>[[tensor(-0.9143+0.5262j), tensor(-0.8846+0.15...</td>\n",
       "      <td>[[tensor(0.8569-1.2288j), tensor(-1.1770-1.180...</td>\n",
       "      <td>[[tensor(0.5714+0.8075j), tensor(-0.0329-0.234...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[tensor(-1.2501+1.1638j), tensor(0.2655-1.256...</td>\n",
       "      <td>[[tensor(0.1878-1.6681j), tensor(1.4101+0.5654...</td>\n",
       "      <td>[[tensor(-0.1287+0.3333j), tensor(0.6849+0.567...</td>\n",
       "      <td>[[tensor(0.0955-1.0764j), tensor(0.8175-0.4965...</td>\n",
       "      <td>[[tensor(-0.4266+0.3778j), tensor(0.8342+0.051...</td>\n",
       "      <td>[[tensor(-0.0540-0.5140j), tensor(0.0464-1.357...</td>\n",
       "      <td>[[tensor(1.1570-1.0600j), tensor(-3.0951+0.478...</td>\n",
       "      <td>[[tensor(1.6532-1.2396j), tensor(2.5600-0.1069...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  [[tensor(-0.0671-0.7584j), tensor(0.7654-1.669...   \n",
       "1  [[tensor(-2.3240+1.3299j), tensor(-1.3996+0.09...   \n",
       "2  [[tensor(0.8616-1.6796j), tensor(0.0656-0.5628...   \n",
       "3  [[tensor(0.5128+2.2246j), tensor(-0.7010-1.415...   \n",
       "4  [[tensor(-1.1951-0.9662j), tensor(1.7508+1.108...   \n",
       "5  [[tensor(-1.2995-2.5753j), tensor(0.2858-2.326...   \n",
       "6  [[tensor(-0.2393-0.1396j), tensor(-0.0497+2.16...   \n",
       "7  [[tensor(0.2745+0.4996j), tensor(0.4409-0.3289...   \n",
       "8  [[tensor(1.1549+1.7577j), tensor(-0.0731+0.357...   \n",
       "9  [[tensor(-1.2501+1.1638j), tensor(0.2655-1.256...   \n",
       "\n",
       "                                                   1  \\\n",
       "0  [[tensor(-0.0850+2.0890j), tensor(0.6860-1.006...   \n",
       "1  [[tensor(0.9684-1.7266j), tensor(-0.6797-1.840...   \n",
       "2  [[tensor(-0.4451+0.3902j), tensor(-1.4060-0.46...   \n",
       "3  [[tensor(-1.1856-0.4819j), tensor(0.6214-1.416...   \n",
       "4  [[tensor(0.1701+0.3513j), tensor(-0.5437-0.729...   \n",
       "5  [[tensor(0.6334-0.2164j), tensor(-2.9397-0.008...   \n",
       "6  [[tensor(-0.3758+1.2095j), tensor(0.3108+0.605...   \n",
       "7  [[tensor(1.4717-1.4084j), tensor(0.8559+0.8322...   \n",
       "8  [[tensor(0.4737-0.2838j), tensor(-0.3717-0.338...   \n",
       "9  [[tensor(0.1878-1.6681j), tensor(1.4101+0.5654...   \n",
       "\n",
       "                                                   2  \\\n",
       "0  [[tensor(-1.4190-0.3194j), tensor(-1.3981-0.36...   \n",
       "1  [[tensor(1.7691-0.2782j), tensor(-0.9194-0.153...   \n",
       "2  [[tensor(-0.3006-2.9138j), tensor(0.8641+0.980...   \n",
       "3  [[tensor(-0.1885-1.3662j), tensor(-0.7833+0.60...   \n",
       "4  [[tensor(0.7469-0.8845j), tensor(0.9412+0.3307...   \n",
       "5  [[tensor(0.4459+1.3150j), tensor(0.4346+1.4968...   \n",
       "6  [[tensor(-0.5330-0.2716j), tensor(-0.1520+0.48...   \n",
       "7  [[tensor(-0.7999-1.4514j), tensor(1.3643-0.084...   \n",
       "8  [[tensor(-0.4688+0.0398j), tensor(0.7929+0.196...   \n",
       "9  [[tensor(-0.1287+0.3333j), tensor(0.6849+0.567...   \n",
       "\n",
       "                                                   3  \\\n",
       "0  [[tensor(-2.0406+1.2129j), tensor(-0.7994+0.01...   \n",
       "1  [[tensor(-1.2872+0.0022j), tensor(-1.2818+1.72...   \n",
       "2  [[tensor(-0.9107+2.1415j), tensor(1.9554+0.650...   \n",
       "3  [[tensor(-0.6910+0.2716j), tensor(-0.6368-0.91...   \n",
       "4  [[tensor(-0.0068+0.3495j), tensor(0.3833+0.256...   \n",
       "5  [[tensor(-0.3480+0.3138j), tensor(-0.5462+0.45...   \n",
       "6  [[tensor(-0.9080+0.7858j), tensor(0.3499-0.972...   \n",
       "7  [[tensor(0.6672-0.8128j), tensor(-1.0016+0.993...   \n",
       "8  [[tensor(1.8209-0.4706j), tensor(-0.0160+0.742...   \n",
       "9  [[tensor(0.0955-1.0764j), tensor(0.8175-0.4965...   \n",
       "\n",
       "                                                   0  \\\n",
       "0  [[tensor(-2.2761-1.4484j), tensor(1.2999+2.947...   \n",
       "1  [[tensor(-0.1527+0.1605j), tensor(0.6668+1.747...   \n",
       "2  [[tensor(0.5721+1.4493j), tensor(-0.4224+0.954...   \n",
       "3  [[tensor(0.5218-0.5860j), tensor(0.1351-0.2889...   \n",
       "4  [[tensor(0.1751-0.2768j), tensor(0.2558-1.0891...   \n",
       "5  [[tensor(-0.1475-1.3746j), tensor(0.2122+0.293...   \n",
       "6  [[tensor(0.5895+2.2349j), tensor(0.2653-3.3129...   \n",
       "7  [[tensor(1.8183+0.4838j), tensor(-0.3537-0.831...   \n",
       "8  [[tensor(2.3053+0.5111j), tensor(-0.5735+2.072...   \n",
       "9  [[tensor(-0.4266+0.3778j), tensor(0.8342+0.051...   \n",
       "\n",
       "                                                   1  \\\n",
       "0  [[tensor(-1.2215+0.9061j), tensor(-0.2374-0.64...   \n",
       "1  [[tensor(0.8145+2.4532j), tensor(0.5506-0.3737...   \n",
       "2  [[tensor(-2.3652+1.0367j), tensor(-0.8970-0.12...   \n",
       "3  [[tensor(1.2143+0.7065j), tensor(-0.1696+0.120...   \n",
       "4  [[tensor(-0.7947-1.2705j), tensor(-0.2561-0.26...   \n",
       "5  [[tensor(1.0587-0.1317j), tensor(0.9242+0.4298...   \n",
       "6  [[tensor(1.5641-1.3597j), tensor(0.5240+0.8918...   \n",
       "7  [[tensor(0.8323+1.6676j), tensor(0.4486+1.1067...   \n",
       "8  [[tensor(-0.9143+0.5262j), tensor(-0.8846+0.15...   \n",
       "9  [[tensor(-0.0540-0.5140j), tensor(0.0464-1.357...   \n",
       "\n",
       "                                                   2  \\\n",
       "0  [[tensor(0.3742+0.6502j), tensor(0.4598-0.5954...   \n",
       "1  [[tensor(0.8166-0.2685j), tensor(3.1040-0.6226...   \n",
       "2  [[tensor(0.9812+1.7056j), tensor(0.7562+0.0377...   \n",
       "3  [[tensor(-0.1198-1.0393j), tensor(-0.8785+2.16...   \n",
       "4  [[tensor(-0.6154-0.4045j), tensor(0.8162+0.045...   \n",
       "5  [[tensor(-0.1584+1.2031j), tensor(0.7313+0.937...   \n",
       "6  [[tensor(-2.5834-0.5254j), tensor(1.2642+0.369...   \n",
       "7  [[tensor(-0.4147-0.1938j), tensor(-0.0886-0.66...   \n",
       "8  [[tensor(0.8569-1.2288j), tensor(-1.1770-1.180...   \n",
       "9  [[tensor(1.1570-1.0600j), tensor(-3.0951+0.478...   \n",
       "\n",
       "                                                   3  \n",
       "0  [[tensor(1.7330-1.3346j), tensor(0.8281+1.9333...  \n",
       "1  [[tensor(-0.4254+2.0138j), tensor(0.5117+1.658...  \n",
       "2  [[tensor(-0.7285-1.4143j), tensor(0.0571-0.711...  \n",
       "3  [[tensor(-0.8914+1.4690j), tensor(0.8811+0.652...  \n",
       "4  [[tensor(-0.6924-0.2615j), tensor(1.9418+0.535...  \n",
       "5  [[tensor(0.1070-0.8492j), tensor(1.1959+0.3698...  \n",
       "6  [[tensor(-0.2199-0.6399j), tensor(-0.8450+1.34...  \n",
       "7  [[tensor(-1.6282-0.8072j), tensor(-0.2779+1.31...  \n",
       "8  [[tensor(0.5714+0.8075j), tensor(-0.0329-0.234...  \n",
       "9  [[tensor(1.6532-1.2396j), tensor(2.5600-0.1069...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8d21638d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, Loss: 0.6345232129096985\n",
      "Epoch 2/1000, Loss: 0.6296367049217224\n",
      "Epoch 3/1000, Loss: 0.6251901388168335\n",
      "Epoch 4/1000, Loss: 0.6206528544425964\n",
      "Epoch 5/1000, Loss: 0.6151571869850159\n",
      "Epoch 6/1000, Loss: 0.6094835996627808\n",
      "Epoch 7/1000, Loss: 0.6036584973335266\n",
      "Epoch 8/1000, Loss: 0.5979498624801636\n",
      "Epoch 9/1000, Loss: 0.5921768546104431\n",
      "Epoch 10/1000, Loss: 0.5857403874397278\n",
      "Epoch 11/1000, Loss: 0.5785773992538452\n",
      "Epoch 12/1000, Loss: 0.5707677006721497\n",
      "Epoch 13/1000, Loss: 0.5608784556388855\n",
      "Epoch 14/1000, Loss: 0.551145076751709\n",
      "Epoch 15/1000, Loss: 0.540895938873291\n",
      "Epoch 16/1000, Loss: 0.5297767519950867\n",
      "Epoch 17/1000, Loss: 0.5182663798332214\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Supervised training\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_supervised\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/Deep-Unfolding-NN/src/CNN.py:114\u001b[0m, in \u001b[0;36mTrainer.train_supervised\u001b[0;34m(self, dataset, num_epochs, batch_size, lr)\u001b[0m\n\u001b[1;32m    112\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets_tensor)\n\u001b[1;32m    113\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m--> 114\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/Deep-Unfolding-NN/lib/python3.10/site-packages/torch/optim/optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/Deep-Unfolding-NN/lib/python3.10/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/miniconda3/envs/Deep-Unfolding-NN/lib/python3.10/site-packages/torch/optim/adam.py:223\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    211\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    213\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    214\u001b[0m         group,\n\u001b[1;32m    215\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    220\u001b[0m         state_steps,\n\u001b[1;32m    221\u001b[0m     )\n\u001b[0;32m--> 223\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda3/envs/Deep-Unfolding-NN/lib/python3.10/site-packages/torch/optim/optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/Deep-Unfolding-NN/lib/python3.10/site-packages/torch/optim/adam.py:784\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    782\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 784\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/Deep-Unfolding-NN/lib/python3.10/site-packages/torch/optim/adam.py:430\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    428\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 430\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    432\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[1;32m    434\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Supervised training\n",
    "tr.train_supervised(dataset=dset, num_epochs=1000, batch_size=2, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b47ed99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(74.8100, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Epoch 1/100, Loss: -7.108625191165061\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "tensor(0., dtype=torch.float64, grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Unsupervised training\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_unsupervised\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/Deep-Unfolding-NN/src/CNN.py:162\u001b[0m, in \u001b[0;36mTrainer.train_unsupervised\u001b[0;34m(self, dataset, num_epochs, batch_size, lr, penalty_coef)\u001b[0m\n\u001b[1;32m    160\u001b[0m     outputs_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtensor_to_dict(outputs)\n\u001b[1;32m    161\u001b[0m     loss \u001b[38;5;241m=\u001b[39m srate_penalty_obj(inputs, outputs_dict, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup\u001b[38;5;241m.\u001b[39mPT, penalty_coef)\n\u001b[0;32m--> 162\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/Deep-Unfolding-NN/lib/python3.10/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/Deep-Unfolding-NN/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/Deep-Unfolding-NN/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Unsupervised training\n",
    "tr.train_unsupervised(dataset=dset, num_epochs=100, batch_size=2, lr=1e-3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep-Unfolding-NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
