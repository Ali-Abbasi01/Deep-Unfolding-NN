{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ec16ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Any\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Get the current working directory\n",
    "scripts_dir = os.getcwd()\n",
    "# Go up one level\n",
    "project_root = os.path.abspath(os.path.join(scripts_dir, '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "import src.utils\n",
    "importlib.reload(src.utils)\n",
    "from src.utils import calculate_sum_rate_sc\n",
    "\n",
    "import src.sc_wmmse\n",
    "importlib.reload(src.sc_wmmse)\n",
    "from src.sc_wmmse import WMMSE_alg_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1810c32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the deep-unfolding NN architecture\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Any\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Define the layer\n",
    "class Layer(nn.Module):\n",
    "    def __init__(self, setup, flagg):\n",
    "        super().__init__()\n",
    "        self.setup = setup\n",
    "        X_U_dict = {}\n",
    "        Y_U_dict = {}\n",
    "        Z_U_dict = {}\n",
    "        O_U_dict = {}\n",
    "        X_W_dict = {}\n",
    "        Y_W_dict = {}\n",
    "        Z_W_dict = {}\n",
    "        X_V_dict = {}\n",
    "        Y_V_dict = {}\n",
    "        Z_V_dict = {}\n",
    "        O_V_dict = {}\n",
    "        for i in range(self.setup.K):\n",
    "            # X_U_dict[str(i)] = nn.Parameter(m01)\n",
    "            # Y_U_dict[str(i)] = nn.Parameter(m02)\n",
    "            # Z_U_dict[str(i)] = nn.Parameter(m03)\n",
    "            # O_U_dict[str(i)] = nn.Parameter(m04)\n",
    "            # X_W_dict[str(i)] = nn.Parameter(m05)\n",
    "            # Y_W_dict[str(i)] = nn.Parameter(m06)\n",
    "            # Z_W_dict[str(i)] = nn.Parameter(m07)\n",
    "            # X_V_dict[str(i)] = nn.Parameter(m08)\n",
    "            # Y_V_dict[str(i)] = nn.Parameter(m09)\n",
    "            # Z_V_dict[str(i)] = nn.Parameter(m010)\n",
    "            # O_V_dict[str(i)] = nn.Parameter(m011)\n",
    "            X_U_dict[str(i)] = nn.Parameter(torch.randn(self.setup.n_rx[i], self.setup.n_rx[i], dtype=torch.cdouble))\n",
    "            Y_U_dict[str(i)] = nn.Parameter(torch.randn(self.setup.n_rx[i], self.setup.n_rx[i], dtype=torch.cdouble))\n",
    "            Z_U_dict[str(i)] = nn.Parameter(torch.randn(self.setup.n_rx[i], self.setup.n_rx[i], dtype=torch.cdouble))\n",
    "            O_U_dict[str(i)] = nn.Parameter(torch.randn(self.setup.n_rx[i], self.setup.d[i], dtype=torch.cdouble))\n",
    "            X_W_dict[str(i)] = nn.Parameter(torch.randn(self.setup.d[i], self.setup.d[i], dtype=torch.cdouble))\n",
    "            Y_W_dict[str(i)] = nn.Parameter(torch.randn(self.setup.d[i], self.setup.d[i], dtype=torch.cdouble))\n",
    "            Z_W_dict[str(i)] = nn.Parameter(torch.randn(self.setup.d[i], self.setup.d[i], dtype=torch.cdouble))\n",
    "            X_V_dict[str(i)] = nn.Parameter(torch.randn(self.setup.n_tx, self.setup.n_tx, dtype=torch.cdouble))\n",
    "            Y_V_dict[str(i)] = nn.Parameter(torch.randn(self.setup.n_tx, self.setup.n_tx, dtype=torch.cdouble))\n",
    "            Z_V_dict[str(i)] = nn.Parameter(torch.randn(self.setup.n_tx, self.setup.n_tx, dtype=torch.cdouble))\n",
    "            O_V_dict[str(i)] = nn.Parameter(torch.randn(self.setup.n_tx, self.setup.d[i], dtype=torch.cdouble))\n",
    "            # X_U_dict[str(i)] = nn.Parameter(100 * torch.rand(self.setup.n_rx[i], self.setup.n_rx[i], dtype=torch.cdouble))\n",
    "            # Y_U_dict[str(i)] = nn.Parameter(100 * torch.rand(self.setup.n_rx[i], self.setup.n_rx[i], dtype=torch.cdouble))\n",
    "            # Z_U_dict[str(i)] = nn.Parameter(100 * torch.rand(self.setup.n_rx[i], self.setup.n_rx[i], dtype=torch.cdouble))\n",
    "            # O_U_dict[str(i)] = nn.Parameter(100 * torch.rand(self.setup.n_rx[i], self.setup.d[i], dtype=torch.cdouble))\n",
    "            # X_W_dict[str(i)] = nn.Parameter(100 * torch.rand(self.setup.d[i], self.setup.d[i], dtype=torch.cdouble))\n",
    "            # Y_W_dict[str(i)] = nn.Parameter(100 * torch.rand(self.setup.d[i], self.setup.d[i], dtype=torch.cdouble))\n",
    "            # Z_W_dict[str(i)] = nn.Parameter(100 * torch.rand(self.setup.d[i], self.setup.d[i], dtype=torch.cdouble))\n",
    "            # X_V_dict[str(i)] = nn.Parameter(100 * torch.rand(self.setup.n_tx, self.setup.n_tx, dtype=torch.cdouble))\n",
    "            # Y_V_dict[str(i)] = nn.Parameter(100 * torch.rand(self.setup.n_tx, self.setup.n_tx, dtype=torch.cdouble))\n",
    "            # Z_V_dict[str(i)] = nn.Parameter(100 * torch.rand(self.setup.n_tx, self.setup.n_tx, dtype=torch.cdouble))\n",
    "            # O_V_dict[str(i)] = nn.Parameter(100 * torch.rand(self.setup.n_tx, self.setup.d[i], dtype=torch.cdouble))\n",
    "        self.X_U = nn.ParameterDict(X_U_dict)\n",
    "        self.Y_U = nn.ParameterDict(Y_U_dict)\n",
    "        self.Z_U = nn.ParameterDict(Z_U_dict)\n",
    "        self.O_U = nn.ParameterDict(O_U_dict)\n",
    "        self.X_W = nn.ParameterDict(X_W_dict)\n",
    "        self.Y_W = nn.ParameterDict(Y_W_dict)\n",
    "        self.Z_W = nn.ParameterDict(Z_W_dict)\n",
    "        self.X_V = nn.ParameterDict(X_V_dict)\n",
    "        self.Y_V = nn.ParameterDict(Y_V_dict)\n",
    "        self.Z_V = nn.ParameterDict(Z_V_dict)\n",
    "        self.O_V = nn.ParameterDict(O_V_dict)\n",
    "\n",
    "\n",
    "    def forward(self, V, H):\n",
    "\n",
    "        # A^+ operator\n",
    "        # def plus(A):\n",
    "        #     diag_inv = 1.0 / A.diagonal(dim1=-2, dim2=-1)\n",
    "        #     A_plus = torch.zeros_like(A)\n",
    "        #     A_plus.diagonal(dim1=-2, dim2=-1).copy_(diag_inv)\n",
    "        #     return A_plus\n",
    "        # def plus(A: torch.Tensor) -> torch.Tensor:\n",
    "        #     \"\"\"\n",
    "        #     Moore-Penrose pseudo-inverse of a diagonal matrix: keeps autograd path.\n",
    "        #     Works batch-wise for ...×N×N tensors.\n",
    "        #     \"\"\"\n",
    "        #     diag = torch.diagonal(A, 0, -2, -1)          # keeps grad wrt A\n",
    "        #     inv  = 1.0 / diag                            # element-wise inverse\n",
    "        #     return torch.diag_embed(inv)\n",
    "        def plus(A):\n",
    "            return A\n",
    "\n",
    "        def proj_power(V):\n",
    "            V_proj = {}\n",
    "            for i in range(num_samples):\n",
    "                V_proj[str(i)] = {}\n",
    "                s = 0\n",
    "                for j in range(self.setup.K):\n",
    "                    s += torch.trace(V[str(i)][str(j)] @ V[str(i)][str(j)].conj().T)\n",
    "                for j in range(self.setup.K):\n",
    "                    V_proj[str(i)][str(j)] = torch.sqrt(self.setup.PT/s) * V[str(i)][str(j)]\n",
    "            return V_proj\n",
    "\n",
    "        # def proj_power(V_in: dict) -> dict:\n",
    "        #     \"\"\"\n",
    "        #     Return a *new* dictionary whose entries are power-normalised copies\n",
    "        #     of the Tx precoders in V_in.  No in-place writes → autograd path stays\n",
    "        #     intact when multiple unfolded layers are stacked.\n",
    "\n",
    "        #     V_in structure (unchanged):  {sample: {user: V_k}}\n",
    "        #     \"\"\"\n",
    "        #     V_out = {}\n",
    "        #     for sample, users in V_in.items():\n",
    "\n",
    "        #         # total power  (trace is complex → take real part)\n",
    "        #         P_tot = sum(torch.trace(v @ v.conj().T).real for v in users.values())\n",
    "        #         scale = torch.sqrt(self.setup.PT / (P_tot + 1e-12))     # +ε avoids div-by-0\n",
    "\n",
    "        #         V_out[sample] = {user: scale * v             # *clone* not needed\n",
    "        #                         for user, v in users.items()}\n",
    "        #     return V_out\n",
    "\n",
    "        # def proj_power_soft(V_in: dict, PT: float, alpha: float = 0.1) -> dict:\n",
    "        #     V_out = {}\n",
    "        #     for i, users in V_in.items():\n",
    "        #         P_tot = sum(torch.trace(v @ v.conj().T).real for v in users.values())\n",
    "        #         scale = torch.sqrt(PT / (P_tot + 1e-12))\n",
    "        #         V_out[str(i)] = {\n",
    "        #             str(k): (1 - alpha) * v + alpha * scale * v for k, v in users.items()\n",
    "        #         }\n",
    "        #     return V_out\n",
    "\n",
    "\n",
    "        num_samples = len(H)\n",
    "\n",
    "        # Calculate A\n",
    "        A = {}\n",
    "        for i in range(num_samples):\n",
    "            A[str(i)] = {}\n",
    "            for j in range(self.setup.K):\n",
    "                s = 0\n",
    "                for k in range(self.setup.K):\n",
    "                    s += torch.trace(V[str(i)][str(k)].conj().T @ V[str(i)][str(k)])\n",
    "                ey = (1/self.setup.PT) * s * torch.eye(self.setup.n_rx[j], dtype=torch.cdouble)\n",
    "                s = 0\n",
    "                for k in range(self.setup.K):\n",
    "                    s += V[str(i)][str(k)] @ V[str(i)][str(k)].conj().T\n",
    "                A[str(i)][str(j)] = ey + H.iloc[i, j] @ s @ H.iloc[i, j].conj().T\n",
    "\n",
    "        # Calculate U\n",
    "        U = {}\n",
    "        for i in range(num_samples):\n",
    "            U[str(i)] = {}\n",
    "            for j in range(self.setup.K):\n",
    "                A_inv = plus(A[str(i)][str(j)]) @ self.X_U[str(j)].to(torch.cdouble) + A[str(i)][str(j)] @ self.Y_U[str(j)].to(torch.cdouble) + self.Z_U[str(j)].to(torch.cdouble)\n",
    "                U[str(i)][str(j)] = A_inv @ H.iloc[i, j] @ V[str(i)][str(j)] + self.O_U[str(j)].to(torch.cdouble)\n",
    "\n",
    "        # Calclate E\n",
    "        E = {}\n",
    "        for i in range(num_samples):\n",
    "            E[str(i)] = {}\n",
    "            for j in range(self.setup.K):\n",
    "                E[str(i)][str(j)] = torch.eye(self.setup.d[j], dtype=torch.cdouble) - U[str(i)][str(j)].conj().T @ H.iloc[i, j] @ V[str(i)][str(j)]\n",
    "        \n",
    "        # Calculate W\n",
    "        W = {}\n",
    "        for i in range(num_samples):\n",
    "            W[str(i)] = {}\n",
    "            for j in range(self.setup.K):\n",
    "                W[str(i)][str(j)] = plus(E[str(i)][str(j)]) @ self.X_W[str(j)].to(torch.cdouble) + E[str(i)][str(j)] @ self.Y_W[str(j)].to(torch.cdouble) + self.Z_W[str(j)].to(torch.cdouble)\n",
    "\n",
    "        # Calculate B\n",
    "        B = {}\n",
    "        for i in range(num_samples):\n",
    "            s = 0\n",
    "            for k in range(self.setup.K):\n",
    "                s += torch.trace(U[str(i)][str(k)] @ W[str(i)][str(k)] @ U[str(i)][str(k)].conj().T)\n",
    "            ey = (1/self.setup.PT) * s * torch.eye(self.setup.n_tx, dtype=torch.cdouble)\n",
    "            s = 0\n",
    "            for k in range(self.setup.K):\n",
    "                s += H.iloc[i, k].conj().T @ U[str(i)][str(k)] @ W[str(i)][str(k)] @ U[str(i)][str(k)].conj().T @ H.iloc[i, k]\n",
    "            B[str(i)] = ey + s\n",
    "                \n",
    "\n",
    "        # Calculate V\n",
    "        V = {}\n",
    "        for i in range(num_samples):\n",
    "            V[str(i)] = {}\n",
    "            for j in range(self.setup.K): \n",
    "                B_inv = plus(B[str(i)]) @ self.X_V[str(j)].to(torch.cdouble) + B[str(i)] @ self.Y_V[str(j)].to(torch.cdouble) + self.Z_V[str(j)].to(torch.cdouble)\n",
    "                V[str(i)][str(j)] = B_inv @ H.iloc[i, j].conj().T @ U[str(i)][str(j)] @ W[str(i)][str(j)] + self.O_V[str(j)].to(torch.cdouble)\n",
    "\n",
    "        # Project V\n",
    "        V_proj = proj_power(V)\n",
    "        # V_proj = proj_power_soft(V, self.setup.PT, alpha=0.1)\n",
    "\n",
    "        return V_proj\n",
    "\n",
    "# Define the deep unfolding NN\n",
    "class DUNN(nn.Module):\n",
    "    def __init__(self, num_layers, setup):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            Layer(setup, i)\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, V, H):\n",
    "        for layer in self.layers:\n",
    "            V = layer(V, H)\n",
    "        return V\n",
    "\n",
    "# Train the model\n",
    "class Trainer:\n",
    "    def __init__(self, model: DUNN, setup, lr: float = 1e-3):\n",
    "        self.setup = setup\n",
    "        self.model = model\n",
    "        self.opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    def train_epoch(self, dset, loss_fn, num_epochs, batch_size):\n",
    "\n",
    "        # Function for initializing V\n",
    "        # def init_V(H_df, setup):\n",
    "        #     num_samples = H_df.shape[0]\n",
    "        #     K = setup.K\n",
    "        #     V_dict = {}\n",
    "\n",
    "        #     for sample_idx in range(num_samples):\n",
    "        #         V_sample = {}\n",
    "        #         H_sample = [H_df.iloc[sample_idx, k] for k in range(K)]\n",
    "\n",
    "        #         for k in range(K):\n",
    "        #             # Create interference channel matrix for all users ≠ k\n",
    "        #             H_interference = torch.cat([H_sample[j] for j in range(K) if j != k], dim=0)\n",
    "\n",
    "        #             # Compute null space of interference channel using SVD\n",
    "        #             _, S, Vh = torch.linalg.svd(H_interference)\n",
    "        #             rank = (S > 1e-6).sum().item()\n",
    "        #             null_space = Vh[rank:].conj().T  # shape: [n_tx, nullity]\n",
    "\n",
    "        #             # Choose as many columns as the number of streams we want (≤ nullity)\n",
    "        #             d_k = min(setup.n_rx[k], null_space.shape[1])\n",
    "        #             V_k = null_space[:, :d_k]\n",
    "\n",
    "        #             V_sample[str(k)] = V_k\n",
    "\n",
    "        #         V_dict[str(sample_idx)] = V_sample\n",
    "        #     return V_dict\n",
    "\n",
    "        def proj_power(V):\n",
    "            for i in range(len(V)):\n",
    "                s = 0\n",
    "                for j in range(self.setup.K):\n",
    "                    s += torch.trace(V[str(i)][str(j)] @ V[str(i)][str(j)].conj().T)\n",
    "                for j in range(self.setup.K):\n",
    "                    V[str(i)][str(j)] = torch.sqrt(self.setup.PT/s) * V[str(i)][str(j)]\n",
    "            return V\n",
    "\n",
    "        def shuffle_and_batch(df, batch_size):\n",
    "            df_shuffled = df.sample(frac=1).reset_index(drop=True)\n",
    "            return [df_shuffled[i:i + batch_size] for i in range(0, len(df_shuffled), batch_size)]\n",
    "\n",
    "        loader = shuffle_and_batch(dset, batch_size)\n",
    "\n",
    "        H_total = dset.iloc[:, :self.setup.K]\n",
    "        V_total_df = dset.iloc[:, self.setup.K:(2*self.setup.K)]\n",
    "        V_total = {\n",
    "                    str(i): {str(j): V_total_df.iloc[i, j] for j in range(V_total_df.shape[1])}\n",
    "                    for i in range(len(V_total_df))\n",
    "                }\n",
    "        r_l = []\n",
    "        for _ in range(num_epochs):\n",
    "            self.model.train()\n",
    "            total_loss = 0.0\n",
    "            for dset_batch in loader:\n",
    "                H_batch = dset_batch.iloc[:, :self.setup.K]\n",
    "                V_init_batch = dset_batch.iloc[:, self.setup.K:(2*self.setup.K)]\n",
    "                V0 = {\n",
    "                    str(i): {str(j): V_init_batch.iloc[i, j] for j in range(V_init_batch.shape[1])}\n",
    "                    for i in range(len(V_init_batch))\n",
    "                }\n",
    "                # H_batch = H_batch.to(torch.complex64)\n",
    "                self.opt.zero_grad()\n",
    "                # Initialize V\n",
    "                # V0 = init_V(H_batch, self.setup)\n",
    "                # V0 = proj_power(V0)\n",
    "                # V0 = V_init\n",
    "                V_pred = self.model(V0, H_batch)\n",
    "                loss = (-1) * loss_fn(H_batch, V_pred, self.setup.PT)\n",
    "                print(loss)\n",
    "                loss.backward()\n",
    "                # print(self.model.layers[0].X_U['0'].grad)\n",
    "                self.opt.step()\n",
    "                total_loss += loss.item()\n",
    "            # r_l.append(loss_fn(H_total, self.model(V_total, H_total), self.setup.PT))\n",
    "\n",
    "        # return total_loss / len(loader)\n",
    "        # return r_l\n",
    "        return V_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502bac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the deep-unfolding NN architecture\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Any\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Define the layer\n",
    "class Layer(nn.Module):\n",
    "    def __init__(self, setup, flagg):\n",
    "        super().__init__()\n",
    "        self.setup = setup\n",
    "        X_U_dict = {}\n",
    "        Y_U_dict = {}\n",
    "        Z_U_dict = {}\n",
    "        O_U_dict = {}\n",
    "        X_W_dict = {}\n",
    "        Y_W_dict = {}\n",
    "        Z_W_dict = {}\n",
    "        X_V_dict = {}\n",
    "        Y_V_dict = {}\n",
    "        Z_V_dict = {}\n",
    "        O_V_dict = {}\n",
    "\n",
    "        if flagg == 0:\n",
    "            print('h')\n",
    "            for i in range(self.setup.K):\n",
    "                X_U_dict[str(i)] = nn.Parameter(m1)\n",
    "                Y_U_dict[str(i)] = nn.Parameter(m2)\n",
    "                Z_U_dict[str(i)] = nn.Parameter(m3)\n",
    "                O_U_dict[str(i)] = nn.Parameter(m4)\n",
    "                X_W_dict[str(i)] = nn.Parameter(m5)\n",
    "                Y_W_dict[str(i)] = nn.Parameter(m6)\n",
    "                Z_W_dict[str(i)] = nn.Parameter(m7)\n",
    "                X_V_dict[str(i)] = nn.Parameter(m8)\n",
    "                Y_V_dict[str(i)] = nn.Parameter(m9)\n",
    "                Z_V_dict[str(i)] = nn.Parameter(m10)\n",
    "                O_V_dict[str(i)] = nn.Parameter(m11)\n",
    "                # X_U_dict[str(i)] = nn.Parameter(torch.randn(self.setup.n_rx[i], self.setup.n_rx[i], dtype=torch.cdouble))\n",
    "                # Y_U_dict[str(i)] = nn.Parameter(torch.randn(self.setup.n_rx[i], self.setup.n_rx[i], dtype=torch.cdouble))\n",
    "                # Z_U_dict[str(i)] = nn.Parameter(torch.randn(self.setup.n_rx[i], self.setup.n_rx[i], dtype=torch.cdouble))\n",
    "                # O_U_dict[str(i)] = nn.Parameter(torch.randn(self.setup.n_rx[i], self.setup.d[i], dtype=torch.cdouble))\n",
    "                # X_W_dict[str(i)] = nn.Parameter(torch.randn(self.setup.d[i], self.setup.d[i], dtype=torch.cdouble))\n",
    "                # Y_W_dict[str(i)] = nn.Parameter(torch.randn(self.setup.d[i], self.setup.d[i], dtype=torch.cdouble))\n",
    "                # Z_W_dict[str(i)] = nn.Parameter(torch.randn(self.setup.d[i], self.setup.d[i], dtype=torch.cdouble))\n",
    "                # X_V_dict[str(i)] = nn.Parameter(torch.randn(self.setup.n_tx, self.setup.n_tx, dtype=torch.cdouble))\n",
    "                # Y_V_dict[str(i)] = nn.Parameter(torch.randn(self.setup.n_tx, self.setup.n_tx, dtype=torch.cdouble))\n",
    "                # Z_V_dict[str(i)] = nn.Parameter(torch.randn(self.setup.n_tx, self.setup.n_tx, dtype=torch.cdouble))\n",
    "                # O_V_dict[str(i)] = nn.Parameter(torch.randn(self.setup.n_tx, self.setup.d[i], dtype=torch.cdouble))\n",
    "                # # X_U_dict[str(i)] = nn.Parameter(100 * torch.rand(self.setup.n_rx[i], self.setup.n_rx[i], dtype=torch.cdouble))\n",
    "                # # Y_U_dict[str(i)] = nn.Parameter(100 * torch.rand(self.setup.n_rx[i], self.setup.n_rx[i], dtype=torch.cdouble))\n",
    "                # # Z_U_dict[str(i)] = nn.Parameter(100 * torch.rand(self.setup.n_rx[i], self.setup.n_rx[i], dtype=torch.cdouble))\n",
    "                # # O_U_dict[str(i)] = nn.Parameter(100 * torch.rand(self.setup.n_rx[i], self.setup.d[i], dtype=torch.cdouble))\n",
    "                # # X_W_dict[str(i)] = nn.Parameter(100 * torch.rand(self.setup.d[i], self.setup.d[i], dtype=torch.cdouble))\n",
    "                # # Y_W_dict[str(i)] = nn.Parameter(100 * torch.rand(self.setup.d[i], self.setup.d[i], dtype=torch.cdouble))\n",
    "                # # Z_W_dict[str(i)] = nn.Parameter(100 * torch.rand(self.setup.d[i], self.setup.d[i], dtype=torch.cdouble))\n",
    "                # # X_V_dict[str(i)] = nn.Parameter(100 * torch.rand(self.setup.n_tx, self.setup.n_tx, dtype=torch.cdouble))\n",
    "                # # Y_V_dict[str(i)] = nn.Parameter(100 * torch.rand(self.setup.n_tx, self.setup.n_tx, dtype=torch.cdouble))\n",
    "                # # Z_V_dict[str(i)] = nn.Parameter(100 * torch.rand(self.setup.n_tx, self.setup.n_tx, dtype=torch.cdouble))\n",
    "                # # O_V_dict[str(i)] = nn.Parameter(100 * torch.rand(self.setup.n_tx, self.setup.d[i], dtype=torch.cdouble))\n",
    "            self.X_U = nn.ParameterDict(X_U_dict)\n",
    "            self.Y_U = nn.ParameterDict(Y_U_dict)\n",
    "            self.Z_U = nn.ParameterDict(Z_U_dict)\n",
    "            self.O_U = nn.ParameterDict(O_U_dict)\n",
    "            self.X_W = nn.ParameterDict(X_W_dict)\n",
    "            self.Y_W = nn.ParameterDict(Y_W_dict)\n",
    "            self.Z_W = nn.ParameterDict(Z_W_dict)\n",
    "            self.X_V = nn.ParameterDict(X_V_dict)\n",
    "            self.Y_V = nn.ParameterDict(Y_V_dict)\n",
    "            self.Z_V = nn.ParameterDict(Z_V_dict)\n",
    "            self.O_V = nn.ParameterDict(O_V_dict)\n",
    "\n",
    "        if flagg == 1:\n",
    "            print('h')\n",
    "            for i in range(self.setup.K):\n",
    "                X_U_dict[str(i)] = nn.Parameter(m01)\n",
    "                Y_U_dict[str(i)] = nn.Parameter(m02)\n",
    "                Z_U_dict[str(i)] = nn.Parameter(m03)\n",
    "                O_U_dict[str(i)] = nn.Parameter(m04)\n",
    "                X_W_dict[str(i)] = nn.Parameter(m05)\n",
    "                Y_W_dict[str(i)] = nn.Parameter(m06)\n",
    "                Z_W_dict[str(i)] = nn.Parameter(m07)\n",
    "                X_V_dict[str(i)] = nn.Parameter(m08)\n",
    "                Y_V_dict[str(i)] = nn.Parameter(m09)\n",
    "                Z_V_dict[str(i)] = nn.Parameter(m010)\n",
    "                O_V_dict[str(i)] = nn.Parameter(m011)\n",
    "                # X_U_dict[str(i)] = nn.Parameter(torch.randn(self.setup.n_rx[i], self.setup.n_rx[i], dtype=torch.cdouble))\n",
    "                # Y_U_dict[str(i)] = nn.Parameter(torch.randn(self.setup.n_rx[i], self.setup.n_rx[i], dtype=torch.cdouble))\n",
    "                # Z_U_dict[str(i)] = nn.Parameter(torch.randn(self.setup.n_rx[i], self.setup.n_rx[i], dtype=torch.cdouble))\n",
    "                # O_U_dict[str(i)] = nn.Parameter(torch.randn(self.setup.n_rx[i], self.setup.d[i], dtype=torch.cdouble))\n",
    "                # X_W_dict[str(i)] = nn.Parameter(torch.randn(self.setup.d[i], self.setup.d[i], dtype=torch.cdouble))\n",
    "                # Y_W_dict[str(i)] = nn.Parameter(torch.randn(self.setup.d[i], self.setup.d[i], dtype=torch.cdouble))\n",
    "                # Z_W_dict[str(i)] = nn.Parameter(torch.randn(self.setup.d[i], self.setup.d[i], dtype=torch.cdouble))\n",
    "                # X_V_dict[str(i)] = nn.Parameter(torch.randn(self.setup.n_tx, self.setup.n_tx, dtype=torch.cdouble))\n",
    "                # Y_V_dict[str(i)] = nn.Parameter(torch.randn(self.setup.n_tx, self.setup.n_tx, dtype=torch.cdouble))\n",
    "                # Z_V_dict[str(i)] = nn.Parameter(torch.randn(self.setup.n_tx, self.setup.n_tx, dtype=torch.cdouble))\n",
    "                # O_V_dict[str(i)] = nn.Parameter(torch.randn(self.setup.n_tx, self.setup.d[i], dtype=torch.cdouble))\n",
    "                # # X_U_dict[str(i)] = nn.Parameter(100 * torch.rand(self.setup.n_rx[i], self.setup.n_rx[i], dtype=torch.cdouble))\n",
    "                # # Y_U_dict[str(i)] = nn.Parameter(100 * torch.rand(self.setup.n_rx[i], self.setup.n_rx[i], dtype=torch.cdouble))\n",
    "                # # Z_U_dict[str(i)] = nn.Parameter(100 * torch.rand(self.setup.n_rx[i], self.setup.n_rx[i], dtype=torch.cdouble))\n",
    "                # # O_U_dict[str(i)] = nn.Parameter(100 * torch.rand(self.setup.n_rx[i], self.setup.d[i], dtype=torch.cdouble))\n",
    "                # # X_W_dict[str(i)] = nn.Parameter(100 * torch.rand(self.setup.d[i], self.setup.d[i], dtype=torch.cdouble))\n",
    "                # # Y_W_dict[str(i)] = nn.Parameter(100 * torch.rand(self.setup.d[i], self.setup.d[i], dtype=torch.cdouble))\n",
    "                # # Z_W_dict[str(i)] = nn.Parameter(100 * torch.rand(self.setup.d[i], self.setup.d[i], dtype=torch.cdouble))\n",
    "                # # X_V_dict[str(i)] = nn.Parameter(100 * torch.rand(self.setup.n_tx, self.setup.n_tx, dtype=torch.cdouble))\n",
    "                # # Y_V_dict[str(i)] = nn.Parameter(100 * torch.rand(self.setup.n_tx, self.setup.n_tx, dtype=torch.cdouble))\n",
    "                # # Z_V_dict[str(i)] = nn.Parameter(100 * torch.rand(self.setup.n_tx, self.setup.n_tx, dtype=torch.cdouble))\n",
    "                # # O_V_dict[str(i)] = nn.Parameter(100 * torch.rand(self.setup.n_tx, self.setup.d[i], dtype=torch.cdouble))\n",
    "            self.X_U = nn.ParameterDict(X_U_dict)\n",
    "            self.Y_U = nn.ParameterDict(Y_U_dict)\n",
    "            self.Z_U = nn.ParameterDict(Z_U_dict)\n",
    "            self.O_U = nn.ParameterDict(O_U_dict)\n",
    "            self.X_W = nn.ParameterDict(X_W_dict)\n",
    "            self.Y_W = nn.ParameterDict(Y_W_dict)\n",
    "            self.Z_W = nn.ParameterDict(Z_W_dict)\n",
    "            self.X_V = nn.ParameterDict(X_V_dict)\n",
    "            self.Y_V = nn.ParameterDict(Y_V_dict)\n",
    "            self.Z_V = nn.ParameterDict(Z_V_dict)\n",
    "            self.O_V = nn.ParameterDict(O_V_dict)\n",
    "\n",
    "\n",
    "    def forward(self, V, H):\n",
    "\n",
    "        # A^+ operator\n",
    "        # def plus(A):\n",
    "        #     diag_inv = 1.0 / A.diagonal(dim1=-2, dim2=-1)\n",
    "        #     A_plus = torch.zeros_like(A)\n",
    "        #     A_plus.diagonal(dim1=-2, dim2=-1).copy_(diag_inv)\n",
    "        #     return A_plus\n",
    "        # def plus(A: torch.Tensor) -> torch.Tensor:\n",
    "        #     \"\"\"\n",
    "        #     Moore-Penrose pseudo-inverse of a diagonal matrix: keeps autograd path.\n",
    "        #     Works batch-wise for ...×N×N tensors.\n",
    "        #     \"\"\"\n",
    "        #     diag = torch.diagonal(A, 0, -2, -1)          # keeps grad wrt A\n",
    "        #     inv  = 1.0 / diag                            # element-wise inverse\n",
    "        #     return torch.diag_embed(inv)\n",
    "        def plus(A):\n",
    "            return A\n",
    "\n",
    "        def proj_power(V):\n",
    "            V_proj = {}\n",
    "            for i in range(num_samples):\n",
    "                V_proj[str(i)] = {}\n",
    "                s = 0\n",
    "                for j in range(self.setup.K):\n",
    "                    s += torch.trace(V[str(i)][str(j)] @ V[str(i)][str(j)].conj().T)\n",
    "                for j in range(self.setup.K):\n",
    "                    V_proj[str(i)][str(j)] = torch.sqrt(self.setup.PT/s) * V[str(i)][str(j)]\n",
    "            return V_proj\n",
    "\n",
    "        # def proj_power(V_in: dict) -> dict:\n",
    "        #     \"\"\"\n",
    "        #     Return a *new* dictionary whose entries are power-normalised copies\n",
    "        #     of the Tx precoders in V_in.  No in-place writes → autograd path stays\n",
    "        #     intact when multiple unfolded layers are stacked.\n",
    "\n",
    "        #     V_in structure (unchanged):  {sample: {user: V_k}}\n",
    "        #     \"\"\"\n",
    "        #     V_out = {}\n",
    "        #     for sample, users in V_in.items():\n",
    "\n",
    "        #         # total power  (trace is complex → take real part)\n",
    "        #         P_tot = sum(torch.trace(v @ v.conj().T).real for v in users.values())\n",
    "        #         scale = torch.sqrt(self.setup.PT / (P_tot + 1e-12))     # +ε avoids div-by-0\n",
    "\n",
    "        #         V_out[sample] = {user: scale * v             # *clone* not needed\n",
    "        #                         for user, v in users.items()}\n",
    "        #     return V_out\n",
    "\n",
    "        # def proj_power_soft(V_in: dict, PT: float, alpha: float = 0.1) -> dict:\n",
    "        #     V_out = {}\n",
    "        #     for i, users in V_in.items():\n",
    "        #         P_tot = sum(torch.trace(v @ v.conj().T).real for v in users.values())\n",
    "        #         scale = torch.sqrt(PT / (P_tot + 1e-12))\n",
    "        #         V_out[str(i)] = {\n",
    "        #             str(k): (1 - alpha) * v + alpha * scale * v for k, v in users.items()\n",
    "        #         }\n",
    "        #     return V_out\n",
    "\n",
    "\n",
    "        num_samples = len(H)\n",
    "\n",
    "        # Calculate A\n",
    "        A = {}\n",
    "        for i in range(num_samples):\n",
    "            A[str(i)] = {}\n",
    "            for j in range(self.setup.K):\n",
    "                s = 0\n",
    "                for k in range(self.setup.K):\n",
    "                    s += torch.trace(V[str(i)][str(k)].conj().T @ V[str(i)][str(k)])\n",
    "                ey = (1/self.setup.PT) * s * torch.eye(self.setup.n_rx[j], dtype=torch.cdouble)\n",
    "                s = 0\n",
    "                for k in range(self.setup.K):\n",
    "                    s += V[str(i)][str(k)] @ V[str(i)][str(k)].conj().T\n",
    "                A[str(i)][str(j)] = ey + H.iloc[i, j] @ s @ H.iloc[i, j].conj().T\n",
    "\n",
    "        # Calculate U\n",
    "        U = {}\n",
    "        for i in range(num_samples):\n",
    "            U[str(i)] = {}\n",
    "            for j in range(self.setup.K):\n",
    "                A_inv = plus(A[str(i)][str(j)]) @ self.X_U[str(j)].to(torch.cdouble) + A[str(i)][str(j)] @ self.Y_U[str(j)].to(torch.cdouble) + self.Z_U[str(j)].to(torch.cdouble)\n",
    "                U[str(i)][str(j)] = A_inv @ H.iloc[i, j] @ V[str(i)][str(j)] + self.O_U[str(j)].to(torch.cdouble)\n",
    "\n",
    "        # Calclate E\n",
    "        E = {}\n",
    "        for i in range(num_samples):\n",
    "            E[str(i)] = {}\n",
    "            for j in range(self.setup.K):\n",
    "                E[str(i)][str(j)] = torch.eye(self.setup.d[j], dtype=torch.cdouble) - U[str(i)][str(j)].conj().T @ H.iloc[i, j] @ V[str(i)][str(j)]\n",
    "        \n",
    "        # Calculate W\n",
    "        W = {}\n",
    "        for i in range(num_samples):\n",
    "            W[str(i)] = {}\n",
    "            for j in range(self.setup.K):\n",
    "                W[str(i)][str(j)] = plus(E[str(i)][str(j)]) @ self.X_W[str(j)].to(torch.cdouble) + E[str(i)][str(j)] @ self.Y_W[str(j)].to(torch.cdouble) + self.Z_W[str(j)].to(torch.cdouble)\n",
    "\n",
    "        # Calculate B\n",
    "        B = {}\n",
    "        for i in range(num_samples):\n",
    "            s = 0\n",
    "            for k in range(self.setup.K):\n",
    "                s += torch.trace(U[str(i)][str(k)] @ W[str(i)][str(k)] @ U[str(i)][str(k)].conj().T)\n",
    "            ey = (1/self.setup.PT) * s * torch.eye(self.setup.n_tx, dtype=torch.cdouble)\n",
    "            s = 0\n",
    "            for k in range(self.setup.K):\n",
    "                s += H.iloc[i, k].conj().T @ U[str(i)][str(k)] @ W[str(i)][str(k)] @ U[str(i)][str(k)].conj().T @ H.iloc[i, k]\n",
    "            B[str(i)] = ey + s\n",
    "                \n",
    "\n",
    "        # Calculate V\n",
    "        V = {}\n",
    "        for i in range(num_samples):\n",
    "            V[str(i)] = {}\n",
    "            for j in range(self.setup.K): \n",
    "                B_inv = plus(B[str(i)]) @ self.X_V[str(j)].to(torch.cdouble) + B[str(i)] @ self.Y_V[str(j)].to(torch.cdouble) + self.Z_V[str(j)].to(torch.cdouble)\n",
    "                V[str(i)][str(j)] = B_inv @ H.iloc[i, j].conj().T @ U[str(i)][str(j)] @ W[str(i)][str(j)] + self.O_V[str(j)].to(torch.cdouble)\n",
    "\n",
    "        # Project V\n",
    "        V_proj = proj_power(V)\n",
    "        # V_proj = proj_power_soft(V, self.setup.PT, alpha=0.1)\n",
    "\n",
    "        return V_proj\n",
    "\n",
    "# Define the deep unfolding NN\n",
    "class DUNN(nn.Module):\n",
    "    def __init__(self, num_layers, setup):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            Layer(setup, i)\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, V, H):\n",
    "        for layer in self.layers:\n",
    "            V = layer(V, H)\n",
    "        return V\n",
    "\n",
    "# Train the model\n",
    "class Trainer:\n",
    "    def __init__(self, model: DUNN, setup, lr: float = 1e-3):\n",
    "        self.setup = setup\n",
    "        self.model = model\n",
    "        self.opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    def train_epoch(self, dset, loss_fn, num_epochs, batch_size):\n",
    "\n",
    "        # Function for initializing V\n",
    "        # def init_V(H_df, setup):\n",
    "        #     num_samples = H_df.shape[0]\n",
    "        #     K = setup.K\n",
    "        #     V_dict = {}\n",
    "\n",
    "        #     for sample_idx in range(num_samples):\n",
    "        #         V_sample = {}\n",
    "        #         H_sample = [H_df.iloc[sample_idx, k] for k in range(K)]\n",
    "\n",
    "        #         for k in range(K):\n",
    "        #             # Create interference channel matrix for all users ≠ k\n",
    "        #             H_interference = torch.cat([H_sample[j] for j in range(K) if j != k], dim=0)\n",
    "\n",
    "        #             # Compute null space of interference channel using SVD\n",
    "        #             _, S, Vh = torch.linalg.svd(H_interference)\n",
    "        #             rank = (S > 1e-6).sum().item()\n",
    "        #             null_space = Vh[rank:].conj().T  # shape: [n_tx, nullity]\n",
    "\n",
    "        #             # Choose as many columns as the number of streams we want (≤ nullity)\n",
    "        #             d_k = min(setup.n_rx[k], null_space.shape[1])\n",
    "        #             V_k = null_space[:, :d_k]\n",
    "\n",
    "        #             V_sample[str(k)] = V_k\n",
    "\n",
    "        #         V_dict[str(sample_idx)] = V_sample\n",
    "        #     return V_dict\n",
    "\n",
    "        def proj_power(V):\n",
    "            for i in range(len(V)):\n",
    "                s = 0\n",
    "                for j in range(self.setup.K):\n",
    "                    s += torch.trace(V[str(i)][str(j)] @ V[str(i)][str(j)].conj().T)\n",
    "                for j in range(self.setup.K):\n",
    "                    V[str(i)][str(j)] = torch.sqrt(self.setup.PT/s) * V[str(i)][str(j)]\n",
    "            return V\n",
    "\n",
    "        def shuffle_and_batch(df, batch_size):\n",
    "            df_shuffled = df.sample(frac=1).reset_index(drop=True)\n",
    "            return [df_shuffled[i:i + batch_size] for i in range(0, len(df_shuffled), batch_size)]\n",
    "\n",
    "        loader = shuffle_and_batch(dset, batch_size)\n",
    "\n",
    "        H_total = dset.iloc[:, :self.setup.K]\n",
    "        V_total_df = dset.iloc[:, self.setup.K:(2*self.setup.K)]\n",
    "        V_total = {\n",
    "                    str(i): {str(j): V_total_df.iloc[i, j] for j in range(V_total_df.shape[1])}\n",
    "                    for i in range(len(V_total_df))\n",
    "                }\n",
    "        r_l = []\n",
    "        for _ in range(num_epochs):\n",
    "            self.model.train()\n",
    "            total_loss = 0.0\n",
    "            for dset_batch in loader:\n",
    "                H_batch = dset_batch.iloc[:, :self.setup.K]\n",
    "                V_init_batch = dset_batch.iloc[:, self.setup.K:(2*self.setup.K)]\n",
    "                V0 = {\n",
    "                    str(i): {str(j): V_init_batch.iloc[i, j] for j in range(V_init_batch.shape[1])}\n",
    "                    for i in range(len(V_init_batch))\n",
    "                }\n",
    "                # H_batch = H_batch.to(torch.complex64)\n",
    "                self.opt.zero_grad()\n",
    "                # Initialize V\n",
    "                # V0 = init_V(H_batch, self.setup)\n",
    "                # V0 = proj_power(V0)\n",
    "                # V0 = V_init\n",
    "                V_pred = self.model(V0, H_batch)\n",
    "                loss = (-1) * loss_fn(H_batch, V_pred, self.setup.PT)\n",
    "                print(loss)\n",
    "                loss.backward()\n",
    "                # print(self.model.layers[0].X_U['0'].grad)\n",
    "                self.opt.step()\n",
    "                total_loss += loss.item()\n",
    "            # r_l.append(loss_fn(H_total, self.model(V_total, H_total), self.setup.PT))\n",
    "\n",
    "        # return total_loss / len(loader)\n",
    "        # return r_l\n",
    "        return V_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b22f17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a10ee35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj_power(V, PT_sc):\n",
    "    num_users_sc = len(V)\n",
    "    # Projects V according to the constraint\n",
    "    alph = torch.sqrt(torch.tensor(PT_sc)) / torch.sqrt(torch.tensor(sum([torch.trace(V[str(k)] @ V[str(k)].conj().T) for k in range(num_users_sc)])))\n",
    "    V_proj = {str(k): alph * V[str(k)] for k in range(num_users_sc)}\n",
    "    return V_proj\n",
    "\n",
    "def init_V(H):\n",
    "    # Initializes V according to Hu's code\n",
    "    V = {}\n",
    "    for k in range(len(H_dict)):\n",
    "        V[str(k)] = (torch.linalg.pinv(H[str(k)] @ H[str(k)].conj().T) @ H[str(k)]).conj().T\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f48bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class setup():\n",
    "    def __init__(self, n_tx, n_rx, num_streams, num_users, PT, sig):\n",
    "        self.n_tx = n_tx\n",
    "        self.n_rx = n_rx\n",
    "        self.d = num_streams\n",
    "        self.K = num_users\n",
    "        self.PT = PT\n",
    "        self.sig = sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6f9940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The setup\n",
    "num_users = 1\n",
    "n_tx = 4\n",
    "n_rx = [2] * num_users\n",
    "d = [2] * num_users\n",
    "PT = 200\n",
    "sig = [1] * num_users\n",
    "alpha = [1] * num_users\n",
    "max_iter_alg = 100\n",
    "tol_alg = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30e0b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for _ in range(1):  # 5 rows\n",
    "    row = {f'user_{i}': torch.randn(n_rx[i], n_tx, dtype=torch.cdouble) for i in range(num_users)}\n",
    "    data.append(row)\n",
    "\n",
    "H = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad228e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_col = []\n",
    "V_init_col = []\n",
    "\n",
    "for idx, row in H.iterrows():\n",
    "    H_dict = {str(i): row[i] for i in range(len(row))}\n",
    "    wmm = WMMSE_alg_sc(K=num_users, n_tx=n_tx, n_rx=n_rx, H=H_dict, PT=PT, sig_k=sig, d=d, alpha=alpha, max_iter_alg=max_iter_alg, tol_alg=tol_alg)\n",
    "    V_init = init_V(H_dict)\n",
    "    V_init_proj = proj_power(V_init, PT)\n",
    "    V_l, U_l, W_l = wmm.algorithm(V_init_proj)\n",
    "    V_init_col.append(V_init_proj)\n",
    "    V_col.append(V_l[-1])\n",
    "\n",
    "V_df = pd.DataFrame(V_col)\n",
    "V_init_df = pd.DataFrame(V_init_col)\n",
    "\n",
    "dset = pd.concat([H, V_init_df, V_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0e640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_rate_l = []\n",
    "for idx, row in H.iterrows():\n",
    "    s_rate = 0\n",
    "    H_dict = {str(i): row[i] for i in range(len(row))}\n",
    "    wmm = WMMSE_alg_sc(K=num_users, n_tx=n_tx, n_rx=n_rx, H=H_dict, PT=PT, sig_k=sig, d=d, alpha=alpha, max_iter_alg=max_iter_alg, tol_alg=tol_alg)\n",
    "    V_init = init_V(H_dict)\n",
    "    V_init_proj = proj_power(V_init, PT)\n",
    "    V_l, U_l, W_l = wmm.algorithm(V_init_proj)\n",
    "    for i in range(num_users):\n",
    "        s_rate += torch.log2(torch.linalg.det(W_l[-1][str(i)]))\n",
    "    s_rate_l.append(s_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07d6437",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_up = setup(n_tx=n_tx, n_rx=n_rx, num_streams=d, num_users=num_users, PT=PT, sig = sig)\n",
    "\n",
    "du = DUNN(num_layers=2, setup=set_up)\n",
    "\n",
    "tr = Trainer(model=du, setup=set_up, lr=1e-1)\n",
    "V_final = tr.train_epoch(dset=dset, loss_fn=sum_rate_loss_BC, num_epochs=500, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3952c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = du.layers[0].X_U['0']\n",
    "m2 = du.layers[0].Y_U['0']\n",
    "m3 = du.layers[0].Z_U['0']\n",
    "m4 = du.layers[0].O_U['0']\n",
    "m5 = du.layers[0].X_W['0']\n",
    "m6 = du.layers[0].Y_W['0']\n",
    "m7 = du.layers[0].Z_W['0']\n",
    "m8 = du.layers[0].X_V['0']\n",
    "m9 = du.layers[0].Y_V['0']\n",
    "m10 = du.layers[0].Z_V['0']\n",
    "m11 = du.layers[0].O_V['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96d50ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_col = []\n",
    "V_init_col = []\n",
    "\n",
    "for idx, row in H.iterrows():\n",
    "    H_dict = {str(i): row[i] for i in range(len(row))}\n",
    "    wmm = WMMSE_alg_sc(K=num_users, n_tx=n_tx, n_rx=n_rx, H=H_dict, PT=PT, sig_k=sig, d=d, alpha=alpha, max_iter_alg=max_iter_alg, tol_alg=tol_alg)\n",
    "    V_init = init_V(H_dict)\n",
    "    V_init_proj = proj_power(V_init, PT)\n",
    "    V_l, U_l, W_l = wmm.algorithm(V_init_proj)\n",
    "    # V_init_col.append(V_init_proj)\n",
    "    V_init_col.append(V_final[str(0)])\n",
    "    V_col.append(V_l[-1])\n",
    "\n",
    "V_df = pd.DataFrame(V_col)\n",
    "V_init_df = pd.DataFrame(V_init_col)\n",
    "\n",
    "dset = pd.concat([H, V_init_df, V_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746e2c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_up = setup(n_tx=n_tx, n_rx=n_rx, num_streams=d, num_users=num_users, PT=PT, sig = sig)\n",
    "\n",
    "du = DUNN(num_layers=1, setup=set_up)\n",
    "\n",
    "tr = Trainer(model=du, setup=set_up, lr=1e-1)\n",
    "V_final = tr.train_epoch(dset=dset, loss_fn=sum_rate_loss_BC, num_epochs=500, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ac94d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m01 = du.layers[0].X_U['0']\n",
    "m02 = du.layers[0].Y_U['0']\n",
    "m03 = du.layers[0].Z_U['0']\n",
    "m04 = du.layers[0].O_U['0']\n",
    "m05 = du.layers[0].X_W['0']\n",
    "m06 = du.layers[0].Y_W['0']\n",
    "m07 = du.layers[0].Z_W['0']\n",
    "m08 = du.layers[0].X_V['0']\n",
    "m09 = du.layers[0].Y_V['0']\n",
    "m010 = du.layers[0].Z_V['0']\n",
    "m011 = du.layers[0].O_V['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78581993",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_up = setup(n_tx=n_tx, n_rx=n_rx, num_streams=d, num_users=num_users, PT=PT, sig = sig)\n",
    "\n",
    "du = DUNN(num_layers=2, setup=set_up)\n",
    "\n",
    "tr = Trainer(model=du, setup=set_up, lr=1e-1)\n",
    "V_final = tr.train_epoch(dset=dset, loss_fn=sum_rate_loss_BC, num_epochs=500, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a6e1a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep-Unfolding-NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
